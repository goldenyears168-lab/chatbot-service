#!/usr/bin/env python3
"""
ä»£ç å¥åº·åº¦å…¨é¢æ£€æŸ¥è„šæœ¬
æ£€æŸ¥ TypeScript é”™è¯¯ã€ä»£ç è´¨é‡ã€ä¾èµ–å…³ç³»ã€æµ‹è¯•è¦†ç›–ç‡ç­‰
"""

import os
import json
import subprocess
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Any
import ast

class CodeHealthChecker:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'typescript': {},
            'eslint': {},
            'eslint_complexity': {},
            'dead_code': {},
            'dependency_health': {},
            'code_quality': {},
            'dependencies': {},
            'file_analysis': {},
            'security': {},
            'performance': {},
            'summary': {}
        }
        
    def run_command(self, cmd: List[str], cwd: str = None) -> Tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd or self.project_root,
                capture_output=True,
                text=True,
                timeout=120
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Command timeout"
        except Exception as e:
            return -1, "", str(e)
    
    def check_typescript(self):
        """æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯...")
        returncode, stdout, stderr = self.run_command(['npx', 'tsc', '--noEmit', '--pretty', 'false'])
        
        errors = []
        warnings = []
        
        if returncode != 0:
            output = stderr + stdout
            lines = output.split('\n')
            for line in lines:
                if 'error TS' in line:
                    errors.append(line.strip())
                elif 'warning TS' in line:
                    warnings.append(line.strip())
        
        self.results['typescript'] = {
            'status': 'pass' if returncode == 0 else 'fail',
            'error_count': len(errors),
            'warning_count': len(warnings),
            'errors': errors[:50],  # é™åˆ¶è¾“å‡º
            'warnings': warnings[:50]
        }
        
        return returncode == 0
    
    def check_eslint(self):
        """æ£€æŸ¥ ESLint é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ ESLint é”™è¯¯...")
        returncode, stdout, stderr = self.run_command(['npm', 'run', 'lint', '--', '--format', 'json'])
        
        issues = []
        error_count = 0
        warning_count = 0
        
        if returncode != 0 or stdout:
            try:
                # ESLint JSON æ ¼å¼è¾“å‡º
                output = stdout or stderr
                if output:
                    # å°è¯•è§£æ JSON
                    try:
                        eslint_data = json.loads(output)
                        for file_path, file_issues in eslint_data.items():
                            if isinstance(file_issues, list):
                                for issue in file_issues:
                                    severity = issue.get('severity', 1)
                                    if severity == 2:
                                        error_count += 1
                                    elif severity == 1:
                                        warning_count += 1
                                    issues.append({
                                        'file': file_path,
                                        'line': issue.get('line', 0),
                                        'column': issue.get('column', 0),
                                        'severity': 'error' if severity == 2 else 'warning',
                                        'message': issue.get('message', ''),
                                        'rule': issue.get('ruleId', '')
                                    })
                    except:
                        # å¦‚æœä¸æ˜¯ JSONï¼Œè§£ææ–‡æœ¬è¾“å‡º
                        for line in output.split('\n'):
                            if line.strip() and ('error' in line.lower() or 'warning' in line.lower()):
                                issues.append({'message': line.strip()})
            except:
                pass
        
        self.results['eslint'] = {
            'status': 'pass' if returncode == 0 and error_count == 0 else 'fail',
            'error_count': error_count,
            'warning_count': warning_count,
            'issue_count': len(issues),
            'issues': issues[:50]
        }
        
        return returncode == 0 and error_count == 0
    
    def check_eslint_complexity(self):
        """æ£€æŸ¥ ESLint å¤æ‚åº¦è§„åˆ™"""
        print("ğŸ” æ£€æŸ¥ ESLint å¤æ‚åº¦è§„åˆ™...")
        
        # è¿è¡Œ ESLint å¹¶æ£€æŸ¥å¤æ‚åº¦ç›¸å…³è§„åˆ™
        returncode, stdout, stderr = self.run_command([
            'npx', 'eslint', 
            '--format', 'json',
            'app', 'lib', 'components', 'types'
        ])
        
        complexity_issues = []
        complexity_rules = ['complexity', 'max-depth', 'max-lines', 'max-lines-per-function', 'max-nested-callbacks', 'max-params']
        
        if stdout:
            try:
                eslint_data = json.loads(stdout)
                for file_path, file_issues in eslint_data.items():
                    if isinstance(file_issues, list):
                        for issue in file_issues:
                            rule_id = issue.get('ruleId', '')
                            if any(rule in rule_id.lower() for rule in complexity_rules):
                                complexity_issues.append({
                                    'file': file_path,
                                    'line': issue.get('line', 0),
                                    'rule': rule_id,
                                    'message': issue.get('message', '')
                                })
            except:
                pass
        
        self.results['eslint_complexity'] = {
            'issue_count': len(complexity_issues),
            'issues': complexity_issues[:30]
        }
    
    def check_dead_code(self):
        """ä½¿ç”¨ ts-prune æ£€æŸ¥æ­»ä»£ç """
        print("ğŸ” æ£€æŸ¥æ­»ä»£ç  (ts-prune)...")
        
        returncode, stdout, stderr = self.run_command(['npx', 'ts-prune'])
        
        dead_code_issues = []
        if stdout:
            lines = stdout.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('Found') and 'node_modules' not in line:
                    # è§£æ ts-prune è¾“å‡ºæ ¼å¼: file.ts:line - exportName
                    if ' - ' in line:
                        parts = line.split(' - ')
                        if len(parts) == 2:
                            file_info = parts[0].split(':')
                            dead_code_issues.append({
                                'file': file_info[0] if file_info else parts[0],
                                'line': int(file_info[1]) if len(file_info) > 1 else 0,
                                'export': parts[1].strip()
                            })
                    else:
                        dead_code_issues.append({'file': line})
        
        self.results['dead_code'] = {
            'status': 'pass' if len(dead_code_issues) == 0 else 'warning',
            'issue_count': len(dead_code_issues),
            'issues': dead_code_issues[:50]
        }
    
    def check_dependency_health(self):
        """ä½¿ç”¨ depcheck æ£€æŸ¥ä¾èµ–å¥åº·"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–å¥åº· (depcheck)...")
        
        returncode, stdout, stderr = self.run_command(['npx', 'depcheck', '--json'])
        
        unused_deps = []
        missing_deps = []
        
        if stdout:
            try:
                depcheck_data = json.loads(stdout)
                unused_deps = depcheck_data.get('dependencies', [])
                missing_deps = list(depcheck_data.get('missing', {}).keys())
            except:
                # å¦‚æœä¸æ˜¯ JSONï¼Œè§£ææ–‡æœ¬è¾“å‡º
                if stdout:
                    for line in stdout.split('\n'):
                        if 'Unused dependencies' in line or 'Missing dependencies' in line:
                            continue
                        line = line.strip()
                        if line and not line.startswith('*'):
                            if 'Missing' in stdout:
                                missing_deps.append(line)
                            else:
                                unused_deps.append(line)
        
        self.results['dependency_health'] = {
            'status': 'pass' if len(unused_deps) == 0 and len(missing_deps) == 0 else 'warning',
            'unused_dependencies': unused_deps[:30],
            'missing_dependencies': missing_deps[:30],
            'unused_count': len(unused_deps),
            'missing_count': len(missing_deps)
        }
    
    def analyze_file_complexity(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å¤æ‚åº¦"""
        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # åŸºæœ¬ç»Ÿè®¡
            total_lines = len(lines)
            code_lines = len([l for l in lines if l.strip() and not l.strip().startswith('//') and not l.strip().startswith('/*')])
            comment_lines = len([l for l in lines if '//' in l or '/*' in l or '*/' in l])
            blank_lines = len([l for l in lines if not l.strip()])
            
            # å¤æ‚åº¦æŒ‡æ ‡
            function_count = len(re.findall(r'(?:function|const|let|var)\s+\w+\s*[=:]', content))
            class_count = len(re.findall(r'class\s+\w+', content))
            import_count = len(re.findall(r'^import\s+', content, re.MULTILINE))
            export_count = len(re.findall(r'^export\s+', content, re.MULTILINE))
            
            # åµŒå¥—æ·±åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
            max_depth = 0
            current_depth = 0
            for char in content:
                if char == '{':
                    current_depth += 1
                    max_depth = max(max_depth, current_depth)
                elif char == '}':
                    current_depth = max(0, current_depth - 1)
            
            # æ–‡ä»¶å¤§å°è­¦å‘Š
            size_warning = None
            file_size_kb = file_path.stat().st_size / 1024
            if file_size_kb > 100:
                size_warning = f"æ–‡ä»¶è¿‡å¤§ ({file_size_kb:.1f} KB)"
            
            return {
                'total_lines': total_lines,
                'code_lines': code_lines,
                'comment_lines': comment_lines,
                'blank_lines': blank_lines,
                'function_count': function_count,
                'class_count': class_count,
                'import_count': import_count,
                'export_count': export_count,
                'max_nesting_depth': max_depth,
                'file_size_kb': round(file_size_kb, 2),
                'size_warning': size_warning,
                'complexity_score': function_count * 2 + class_count * 3 + max_depth * 2
            }
        except Exception as e:
            return {'error': str(e)}
    
    def analyze_code_quality(self):
        """åˆ†æä»£ç è´¨é‡"""
        print("ğŸ” åˆ†æä»£ç è´¨é‡...")
        
        source_dirs = ['app', 'lib', 'components', 'types']
        files_analyzed = []
        issues = []
        
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path):
                        continue
                    
                    analysis = self.analyze_file_complexity(file_path)
                    if 'error' not in analysis:
                        files_analyzed.append({
                            'path': str(file_path.relative_to(self.project_root)),
                            **analysis
                        })
                        
                        # æ£€æŸ¥æ½œåœ¨é—®é¢˜
                        if analysis.get('complexity_score', 0) > 50:
                            issues.append(f"{file_path.relative_to(self.project_root)}: å¤æ‚åº¦è¾ƒé«˜ (score: {analysis['complexity_score']})")
                        if analysis.get('max_nesting_depth', 0) > 5:
                            issues.append(f"{file_path.relative_to(self.project_root)}: åµŒå¥—æ·±åº¦è¿‡æ·± ({analysis['max_nesting_depth']})")
                        if analysis.get('size_warning'):
                            issues.append(f"{file_path.relative_to(self.project_root)}: {analysis['size_warning']}")
        
        # ç»Ÿè®¡
        total_files = len(files_analyzed)
        avg_complexity = sum(f.get('complexity_score', 0) for f in files_analyzed) / total_files if total_files > 0 else 0
        large_files = [f for f in files_analyzed if f.get('file_size_kb', 0) > 50]
        complex_files = [f for f in files_analyzed if f.get('complexity_score', 0) > 30]
        
        # ä»£ç è¡Œæ•°ç»Ÿè®¡
        total_lines = sum(f.get('total_lines', 0) for f in files_analyzed)
        total_code_lines = sum(f.get('code_lines', 0) for f in files_analyzed)
        total_comment_lines = sum(f.get('comment_lines', 0) for f in files_analyzed)
        total_blank_lines = sum(f.get('blank_lines', 0) for f in files_analyzed)
        
        # å‡½æ•°å’Œç±»ç»Ÿè®¡
        total_functions = sum(f.get('function_count', 0) for f in files_analyzed)
        total_classes = sum(f.get('class_count', 0) for f in files_analyzed)
        total_imports = sum(f.get('import_count', 0) for f in files_analyzed)
        total_exports = sum(f.get('export_count', 0) for f in files_analyzed)
        
        # æ–‡ä»¶å¤§å°åˆ†å¸ƒ
        small_files = len([f for f in files_analyzed if f.get('file_size_kb', 0) < 10])
        medium_files = len([f for f in files_analyzed if 10 <= f.get('file_size_kb', 0) < 30])
        large_files_count = len([f for f in files_analyzed if f.get('file_size_kb', 0) >= 30])
        
        self.results['code_quality'] = {
            'total_files_analyzed': total_files,
            'average_complexity': round(avg_complexity, 2),
            'large_files_count': len(large_files),
            'complex_files_count': len(complex_files),
            'large_files': [{'path': f['path'], 'size_kb': f['file_size_kb']} for f in large_files[:10]],
            'complex_files': [{'path': f['path'], 'score': f['complexity_score']} for f in complex_files[:10]],
            'issues': issues[:50],
            'code_statistics': {
                'total_lines': total_lines,
                'total_code_lines': total_code_lines,
                'total_comment_lines': total_comment_lines,
                'total_blank_lines': total_blank_lines,
                'total_functions': total_functions,
                'total_classes': total_classes,
                'total_imports': total_imports,
                'total_exports': total_exports,
                'file_size_distribution': {
                    'small': small_files,
                    'medium': medium_files,
                    'large': large_files_count
                }
            }
        }
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–å…³ç³»"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–å…³ç³»...")
        
        package_json = self.project_root / 'package.json'
        if not package_json.exists():
            return
        
        with open(package_json, 'r', encoding='utf-8') as f:
            package_data = json.load(f)
        
        dependencies = package_data.get('dependencies', {})
        dev_dependencies = package_data.get('devDependencies', {})
        
        # æ£€æŸ¥è¿‡æ—¶çš„ä¾èµ–
        outdated = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'outdated', '--json'])
            if returncode == 0 and stdout:
                try:
                    outdated_data = json.loads(stdout)
                    outdated = list(outdated_data.keys())
                except:
                    pass
        except:
            pass
        
        # æ£€æŸ¥å®‰å…¨æ¼æ´
        vulnerabilities = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'audit', '--json'])
            if returncode != 0 and stdout:
                try:
                    audit_data = json.loads(stdout)
                    if 'vulnerabilities' in audit_data:
                        for vuln_id, vuln_data in audit_data['vulnerabilities'].items():
                            if isinstance(vuln_data, dict) and vuln_data.get('severity'):
                                vulnerabilities.append({
                                    'id': vuln_id,
                                    'severity': vuln_data.get('severity'),
                                    'title': vuln_data.get('title', ''),
                                    'via': vuln_data.get('via', [])
                                })
                except:
                    pass
        except:
            pass
        
        self.results['dependencies'] = {
            'total_dependencies': len(dependencies),
            'total_dev_dependencies': len(dev_dependencies),
            'outdated_count': len(outdated),
            'outdated_packages': outdated[:20],
            'vulnerabilities_count': len(vulnerabilities),
            'vulnerabilities': vulnerabilities[:20]
        }
    
    def check_unused_imports(self):
        """æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥ï¼ˆé€šè¿‡ TypeScript æ£€æŸ¥ï¼‰"""
        print("ğŸ” æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥...")
        
        unused_issues = []
        returncode, stdout, stderr = self.run_command(['npx', 'tsc', '--noEmit', '--pretty', 'false'])
        
        if returncode != 0:
            output = stderr + stdout
            for line in output.split('\n'):
                if 'is declared but its value is never read' in line or 'is declared but never used' in line:
                    unused_issues.append(line.strip())
        
        self.results['code_quality']['unused_imports'] = {
            'count': len(unused_issues),
            'issues': unused_issues[:30]
        }
    
    def check_security(self):
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        print("ğŸ” æ£€æŸ¥å®‰å…¨é—®é¢˜...")
        
        security_issues = []
        
        # æ£€æŸ¥ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
        sensitive_patterns = [
            (r'password\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†ç '),
            (r'api[_-]?key\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  API Key'),
            (r'secret\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†é’¥'),
            (r'token\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  Token'),
        ]
        
        source_dirs = ['app', 'lib', 'components']
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx', 'js', 'jsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path) or '__tests__' in str(file_path):
                        continue
                
                try:
                    content = file_path.read_text(encoding='utf-8')
                    for pattern, issue_type in sensitive_patterns:
                        matches = re.finditer(pattern, content, re.IGNORECASE)
                        for match in matches:
                            # æ’é™¤æ˜æ˜¾çš„ç¤ºä¾‹æˆ–æ³¨é‡Š
                            if 'example' not in match.group(0).lower() and 'TODO' not in match.group(0):
                                security_issues.append({
                                    'file': str(file_path.relative_to(self.project_root)),
                                    'type': issue_type,
                                    'line': content[:match.start()].count('\n') + 1
                                })
                except:
                    pass
        
        self.results['security'] = {
            'hardcoded_secrets_count': len(security_issues),
            'issues': security_issues[:30]
        }
    
    def check_test_coverage(self):
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡...")
        
        test_files = list((self.project_root / 'lib' / '__tests__').glob('*.test.ts'))
        test_count = len(test_files)
        
        # å°è¯•è¿è¡Œæµ‹è¯•
        test_status = 'unknown'
        test_output = ''
        try:
            returncode, stdout, stderr = self.run_command(['npm', 'test', '--', '--passWithNoTests'])
            test_status = 'pass' if returncode == 0 else 'fail'
            test_output = stdout + stderr
        except:
            pass
        
        self.results['code_quality']['testing'] = {
            'test_files_count': test_count,
            'test_status': test_status,
            'test_files': [str(f.name) for f in test_files]
        }
    
    def generate_summary(self):
        """ç”Ÿæˆæ€»ç»“"""
        summary = {
            'overall_status': 'pass',
            'issues_found': 0,
            'critical_issues': [],
            'warnings': []
        }
        
        # TypeScript é”™è¯¯
        if self.results['typescript'].get('error_count', 0) > 0:
            summary['issues_found'] += self.results['typescript']['error_count']
            summary['critical_issues'].append(f"TypeScript é”™è¯¯: {self.results['typescript']['error_count']} ä¸ª")
            summary['overall_status'] = 'fail'
        
        # ESLint é”™è¯¯
        eslint_errors = self.results['eslint'].get('error_count', 0)
        eslint_warnings = self.results['eslint'].get('warning_count', 0)
        if eslint_errors > 0:
            summary['issues_found'] += eslint_errors
            summary['critical_issues'].append(f"ESLint é”™è¯¯: {eslint_errors} ä¸ª")
            summary['overall_status'] = 'fail'
        if eslint_warnings > 0:
            summary['issues_found'] += eslint_warnings
            summary['warnings'].append(f"ESLint è­¦å‘Š: {eslint_warnings} ä¸ª")
        
        # ESLint å¤æ‚åº¦é—®é¢˜
        complexity_issues = self.results['eslint_complexity'].get('issue_count', 0)
        if complexity_issues > 0:
            summary['issues_found'] += complexity_issues
            summary['warnings'].append(f"ESLint å¤æ‚åº¦é—®é¢˜: {complexity_issues} ä¸ª")
        
        # æ­»ä»£ç 
        dead_code_count = self.results['dead_code'].get('issue_count', 0)
        if dead_code_count > 0:
            summary['issues_found'] += dead_code_count
            summary['warnings'].append(f"æ­»ä»£ç : {dead_code_count} ä¸ªæœªä½¿ç”¨çš„å¯¼å‡º")
        
        # ä¾èµ–å¥åº·
        unused_deps = self.results['dependency_health'].get('unused_count', 0)
        missing_deps = self.results['dependency_health'].get('missing_count', 0)
        if unused_deps > 0:
            summary['issues_found'] += unused_deps
            summary['warnings'].append(f"æœªä½¿ç”¨çš„ä¾èµ–: {unused_deps} ä¸ª")
        if missing_deps > 0:
            summary['issues_found'] += missing_deps
            summary['warnings'].append(f"ç¼ºå¤±çš„ä¾èµ–: {missing_deps} ä¸ª")
        
        # å®‰å…¨é—®é¢˜
        if self.results['security'].get('hardcoded_secrets_count', 0) > 0:
            summary['issues_found'] += self.results['security']['hardcoded_secrets_count']
            summary['critical_issues'].append(f"å®‰å…¨é—®é¢˜: {self.results['security']['hardcoded_secrets_count']} ä¸ªæ½œåœ¨ç¡¬ç¼–ç å¯†é’¥")
            summary['overall_status'] = 'fail'
        
        # ä¾èµ–æ¼æ´
        if self.results['dependencies'].get('vulnerabilities_count', 0) > 0:
            summary['issues_found'] += self.results['dependencies']['vulnerabilities_count']
            summary['warnings'].append(f"ä¾èµ–æ¼æ´: {self.results['dependencies']['vulnerabilities_count']} ä¸ª")
        
        # æœªä½¿ç”¨çš„å¯¼å…¥
        unused_count = self.results['code_quality'].get('unused_imports', {}).get('count', 0)
        if unused_count > 0:
            summary['issues_found'] += unused_count
            summary['warnings'].append(f"æœªä½¿ç”¨çš„å¯¼å…¥: {unused_count} ä¸ª")
        
        self.results['summary'] = summary
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹ä»£ç å¥åº·åº¦æ£€æŸ¥...\n")
        
        # åŸºç¡€æ£€æŸ¥
        self.check_typescript()
        self.check_eslint()
        self.check_eslint_complexity()
        
        # ä»£ç è´¨é‡æ£€æŸ¥
        self.analyze_code_quality()
        self.check_unused_imports()
        self.check_dead_code()
        
        # ä¾èµ–æ£€æŸ¥
        self.check_dependencies()
        self.check_dependency_health()
        
        # å®‰å…¨å’Œæµ‹è¯•
        self.check_security()
        self.check_test_coverage()
        
        # ç”Ÿæˆæ€»ç»“
        self.generate_summary()
        
        print("\nâœ… æ£€æŸ¥å®Œæˆ!")
    
    def generate_markdown_report(self) -> str:
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        md = []
        md.append("# ä»£ç å¥åº·åº¦æ£€æŸ¥æŠ¥å‘Š")
        md.append("")
        md.append(f"**ç”Ÿæˆæ—¶é—´**: {self.results['timestamp']}")
        md.append("")
        
        # æ€»ç»“
        summary = self.results['summary']
        status_emoji = "âŒ" if summary['overall_status'] == 'fail' else "âœ…"
        md.append(f"## ğŸ“Š æ€»ä½“çŠ¶æ€: {status_emoji} {summary['overall_status'].upper()}")
        md.append("")
        md.append(f"- **å‘ç°é—®é¢˜æ€»æ•°**: {summary['issues_found']}")
        md.append(f"- **ä¸¥é‡é—®é¢˜**: {len(summary['critical_issues'])}")
        md.append(f"- **è­¦å‘Š**: {len(summary['warnings'])}")
        md.append("")
        
        if summary['critical_issues']:
            md.append("### âš ï¸ ä¸¥é‡é—®é¢˜")
            for issue in summary['critical_issues']:
                md.append(f"- {issue}")
            md.append("")
        
        if summary['warnings']:
            md.append("### âš ï¸ è­¦å‘Š")
            for warning in summary['warnings']:
                md.append(f"- {warning}")
            md.append("")
        
        # TypeScript æ£€æŸ¥
        md.append("## ğŸ”· TypeScript æ£€æŸ¥")
        md.append("")
        ts_result = self.results['typescript']
        status_emoji = "âœ…" if ts_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {ts_result.get('status', 'unknown').upper()}")
        md.append(f"- **é”™è¯¯æ•°**: {ts_result.get('error_count', 0)}")
        md.append(f"- **è­¦å‘Šæ•°**: {ts_result.get('warning_count', 0)}")
        md.append("")
        
        if ts_result.get('errors'):
            md.append("### é”™è¯¯åˆ—è¡¨ (å‰ 20 ä¸ª)")
            for error in ts_result['errors'][:20]:
                md.append(f"- `{error}`")
            md.append("")
        
        # ESLint æ£€æŸ¥
        md.append("## ğŸ”¶ ESLint æ£€æŸ¥")
        md.append("")
        eslint_result = self.results['eslint']
        status_emoji = "âœ…" if eslint_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {eslint_result.get('status', 'unknown').upper()}")
        md.append(f"- **é”™è¯¯æ•°**: {eslint_result.get('error_count', 0)}")
        md.append(f"- **è­¦å‘Šæ•°**: {eslint_result.get('warning_count', 0)}")
        md.append(f"- **æ€»é—®é¢˜æ•°**: {eslint_result.get('issue_count', 0)}")
        md.append("")
        
        if eslint_result.get('issues'):
            md.append("### ä¸»è¦é—®é¢˜ (å‰ 10 ä¸ª)")
            for issue in eslint_result['issues'][:10]:
                if isinstance(issue, dict):
                    md.append(f"- `{issue.get('file', 'unknown')}:{issue.get('line', 0)}` - {issue.get('message', '')} [{issue.get('rule', '')}]")
                else:
                    md.append(f"- {issue}")
            md.append("")
        
        # ESLint å¤æ‚åº¦æ£€æŸ¥
        complexity_result = self.results.get('eslint_complexity', {})
        if complexity_result.get('issue_count', 0) > 0:
            md.append("### ğŸ” å¤æ‚åº¦è§„åˆ™æ£€æŸ¥")
            md.append("")
            md.append(f"- **å¤æ‚åº¦é—®é¢˜æ•°**: {complexity_result.get('issue_count', 0)}")
            if complexity_result.get('issues'):
                md.append("### å¤æ‚åº¦é—®é¢˜ (å‰ 10 ä¸ª)")
                for issue in complexity_result['issues'][:10]:
                    md.append(f"- `{issue.get('file', 'unknown')}:{issue.get('line', 0)}` - {issue.get('rule', '')}: {issue.get('message', '')}")
                md.append("")
        
        # æ­»ä»£ç æ£€æŸ¥
        md.append("## ğŸ’€ æ­»ä»£ç æ£€æŸ¥ (ts-prune)")
        md.append("")
        dead_code_result = self.results.get('dead_code', {})
        status_emoji = "âœ…" if dead_code_result.get('status') == 'pass' else "âš ï¸"
        md.append(f"**çŠ¶æ€**: {status_emoji} {dead_code_result.get('status', 'unknown').upper()}")
        md.append(f"- **æœªä½¿ç”¨çš„å¯¼å‡º**: {dead_code_result.get('issue_count', 0)}")
        md.append("")
        
        if dead_code_result.get('issues'):
            md.append("### æœªä½¿ç”¨çš„å¯¼å‡º (å‰ 20 ä¸ª)")
            for issue in dead_code_result['issues'][:20]:
                if isinstance(issue, dict):
                    export_name = issue.get('export', 'unknown')
                    file_path = issue.get('file', 'unknown')
                    line = issue.get('line', 0)
                    if line > 0:
                        md.append(f"- `{file_path}:{line}` - {export_name}")
                    else:
                        md.append(f"- `{file_path}` - {export_name}")
                else:
                    md.append(f"- {issue}")
            md.append("")
        
        # ä¾èµ–å¥åº·æ£€æŸ¥
        md.append("## ğŸ“¦ ä¾èµ–å¥åº·æ£€æŸ¥ (depcheck)")
        md.append("")
        dep_health_result = self.results.get('dependency_health', {})
        status_emoji = "âœ…" if dep_health_result.get('status') == 'pass' else "âš ï¸"
        md.append(f"**çŠ¶æ€**: {status_emoji} {dep_health_result.get('status', 'unknown').upper()}")
        md.append(f"- **æœªä½¿ç”¨çš„ä¾èµ–**: {dep_health_result.get('unused_count', 0)}")
        md.append(f"- **ç¼ºå¤±çš„ä¾èµ–**: {dep_health_result.get('missing_count', 0)}")
        md.append("")
        
        if dep_health_result.get('unused_dependencies'):
            md.append("### æœªä½¿ç”¨çš„ä¾èµ–")
            for dep in dep_health_result['unused_dependencies'][:20]:
                md.append(f"- `{dep}`")
            md.append("")
        
        if dep_health_result.get('missing_dependencies'):
            md.append("### ç¼ºå¤±çš„ä¾èµ–")
            for dep in dep_health_result['missing_dependencies'][:20]:
                md.append(f"- `{dep}`")
            md.append("")
        
        # ä»£ç è´¨é‡
        md.append("## ğŸ“ˆ ä»£ç è´¨é‡åˆ†æ")
        md.append("")
        cq = self.results['code_quality']
        md.append(f"- **åˆ†ææ–‡ä»¶æ•°**: {cq.get('total_files_analyzed', 0)}")
        md.append(f"- **å¹³å‡å¤æ‚åº¦**: {cq.get('average_complexity', 0)}")
        md.append(f"- **å¤§æ–‡ä»¶æ•°** (>50KB): {cq.get('large_files_count', 0)}")
        md.append(f"- **å¤æ‚æ–‡ä»¶æ•°** (score>30): {cq.get('complex_files_count', 0)}")
        md.append("")
        
        # ä»£ç ç»Ÿè®¡
        stats = cq.get('code_statistics', {})
        if stats:
            md.append("### ä»£ç ç»Ÿè®¡")
            md.append("")
            md.append(f"- **æ€»è¡Œæ•°**: {stats.get('total_lines', 0):,}")
            md.append(f"- **ä»£ç è¡Œæ•°**: {stats.get('total_code_lines', 0):,}")
            md.append(f"- **æ³¨é‡Šè¡Œæ•°**: {stats.get('total_comment_lines', 0):,}")
            md.append(f"- **ç©ºè¡Œæ•°**: {stats.get('total_blank_lines', 0):,}")
            md.append(f"- **å‡½æ•°æ•°**: {stats.get('total_functions', 0)}")
            md.append(f"- **ç±»æ•°**: {stats.get('total_classes', 0)}")
            md.append(f"- **å¯¼å…¥æ•°**: {stats.get('total_imports', 0)}")
            md.append(f"- **å¯¼å‡ºæ•°**: {stats.get('total_exports', 0)}")
            md.append("")
            
            dist = stats.get('file_size_distribution', {})
            if dist:
                md.append("### æ–‡ä»¶å¤§å°åˆ†å¸ƒ")
                md.append("")
                md.append(f"- **å°æ–‡ä»¶** (<10KB): {dist.get('small', 0)}")
                md.append(f"- **ä¸­æ–‡ä»¶** (10-30KB): {dist.get('medium', 0)}")
                md.append(f"- **å¤§æ–‡ä»¶** (â‰¥30KB): {dist.get('large', 0)}")
                md.append("")
        
        if cq.get('large_files'):
            md.append("### å¤§æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['large_files']:
                md.append(f"- `{file_info['path']}` ({file_info['size_kb']} KB)")
            md.append("")
        
        if cq.get('complex_files'):
            md.append("### å¤æ‚æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['complex_files']:
                md.append(f"- `{file_info['path']}` (å¤æ‚åº¦: {file_info['score']})")
            md.append("")
        
        unused_imports = cq.get('unused_imports', {})
        if unused_imports.get('count', 0) > 0:
            md.append(f"### æœªä½¿ç”¨çš„å¯¼å…¥ ({unused_imports['count']} ä¸ª)")
            for issue in unused_imports.get('issues', [])[:20]:
                md.append(f"- `{issue}`")
            md.append("")
        
        # ä¾èµ–å…³ç³»
        md.append("## ğŸ“¦ ä¾èµ–å…³ç³»")
        md.append("")
        deps = self.results['dependencies']
        md.append(f"- **ç”Ÿäº§ä¾èµ–**: {deps.get('total_dependencies', 0)}")
        md.append(f"- **å¼€å‘ä¾èµ–**: {deps.get('total_dev_dependencies', 0)}")
        md.append(f"- **è¿‡æ—¶åŒ…æ•°**: {deps.get('outdated_count', 0)}")
        md.append(f"- **å®‰å…¨æ¼æ´**: {deps.get('vulnerabilities_count', 0)}")
        md.append("")
        
        if deps.get('vulnerabilities'):
            md.append("### å®‰å…¨æ¼æ´")
            for vuln in deps['vulnerabilities'][:10]:
                md.append(f"- **{vuln.get('id', 'Unknown')}** ({vuln.get('severity', 'unknown')})")
                if vuln.get('title'):
                    md.append(f"  - {vuln['title']}")
            md.append("")
        
        # å®‰å…¨é—®é¢˜
        md.append("## ğŸ”’ å®‰å…¨æ£€æŸ¥")
        md.append("")
        sec = self.results['security']
        md.append(f"- **æ½œåœ¨ç¡¬ç¼–ç å¯†é’¥**: {sec.get('hardcoded_secrets_count', 0)}")
        md.append("")
        
        if sec.get('issues'):
            md.append("### æ½œåœ¨å®‰å…¨é—®é¢˜")
            for issue in sec['issues'][:20]:
                md.append(f"- `{issue['file']}:{issue['line']}` - {issue['type']}")
            md.append("")
        
        # æµ‹è¯•
        md.append("## ğŸ§ª æµ‹è¯•")
        md.append("")
        testing = cq.get('testing', {})
        md.append(f"- **æµ‹è¯•æ–‡ä»¶æ•°**: {testing.get('test_files_count', 0)}")
        md.append(f"- **æµ‹è¯•çŠ¶æ€**: {testing.get('test_status', 'unknown')}")
        if testing.get('test_files'):
            md.append("### æµ‹è¯•æ–‡ä»¶åˆ—è¡¨")
            for test_file in testing['test_files']:
                md.append(f"- `{test_file}`")
            md.append("")
        
        # å»ºè®®
        md.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
        md.append("")
        
        suggestions = []
        if ts_result.get('error_count', 0) > 0:
            suggestions.append("ä¿®å¤æ‰€æœ‰ TypeScript ç¼–è¯‘é”™è¯¯")
        if eslint_result.get('issue_count', 0) > 0:
            suggestions.append("ä¿®å¤ ESLint ä»£ç é£æ ¼é—®é¢˜")
        if deps.get('vulnerabilities_count', 0) > 0:
            suggestions.append("æ›´æ–°æœ‰å®‰å…¨æ¼æ´çš„ä¾èµ–åŒ…")
        if unused_imports.get('count', 0) > 0:
            suggestions.append("æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥")
        if cq.get('complex_files_count', 0) > 0:
            suggestions.append("é‡æ„å¤æ‚åº¦è¿‡é«˜çš„æ–‡ä»¶ï¼Œæé«˜å¯ç»´æŠ¤æ€§")
        if sec.get('hardcoded_secrets_count', 0) > 0:
            suggestions.append("ç§»é™¤ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡")
        if testing.get('test_files_count', 0) < 5:
            suggestions.append("å¢åŠ æµ‹è¯•è¦†ç›–ç‡ï¼Œæé«˜ä»£ç è´¨é‡")
        
        if suggestions:
            for i, suggestion in enumerate(suggestions, 1):
                md.append(f"{i}. {suggestion}")
        else:
            md.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
        md.append("")
        md.append("---")
        md.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.results['timestamp']}*")
        
        return "\n".join(md)


def main():
    project_root = Path(__file__).parent.parent
    checker = CodeHealthChecker(str(project_root))
    
    checker.run_all_checks()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_markdown_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = project_root / 'CODE_HEALTH_REPORT.md'
    report_path.write_text(report, encoding='utf-8')
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print("\n" + "="*60)
    print(report)
    print("="*60)


if __name__ == '__main__':
    main()

