#!/usr/bin/env python3
"""
ä»£ç å¥åº·åº¦å…¨é¢æ£€æŸ¥è„šæœ¬
æ£€æŸ¥ TypeScript é”™è¯¯ã€ä»£ç è´¨é‡ã€ä¾èµ–å…³ç³»ã€æµ‹è¯•è¦†ç›–ç‡ç­‰
"""

import os
import json
import subprocess
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Any
import ast

class CodeHealthChecker:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'typescript': {},
            'eslint': {},
            'code_quality': {},
            'dependencies': {},
            'file_analysis': {},
            'security': {},
            'performance': {},
            'summary': {}
        }
        
    def run_command(self, cmd: List[str], cwd: str = None) -> Tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd or self.project_root,
                capture_output=True,
                text=True,
                timeout=120
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Command timeout"
        except Exception as e:
            return -1, "", str(e)
    
    def check_typescript(self):
        """æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯...")
        returncode, stdout, stderr = self.run_command(['npx', 'tsc', '--noEmit', '--pretty', 'false'])
        
        errors = []
        warnings = []
        
        if returncode != 0:
            output = stderr + stdout
            lines = output.split('\n')
            for line in lines:
                if 'error TS' in line:
                    errors.append(line.strip())
                elif 'warning TS' in line:
                    warnings.append(line.strip())
        
        self.results['typescript'] = {
            'status': 'pass' if returncode == 0 else 'fail',
            'error_count': len(errors),
            'warning_count': len(warnings),
            'errors': errors[:50],  # é™åˆ¶è¾“å‡º
            'warnings': warnings[:50]
        }
        
        return returncode == 0
    
    def check_eslint(self):
        """æ£€æŸ¥ ESLint é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ ESLint é”™è¯¯...")
        returncode, stdout, stderr = self.run_command(['npm', 'run', 'lint', '--', '--format', 'json'])
        
        issues = []
        if returncode != 0:
            try:
                # ESLint JSON æ ¼å¼è¾“å‡º
                output = stdout or stderr
                if output:
                    # å°è¯•è§£æ JSON
                    try:
                        eslint_data = json.loads(output)
                        for file_path, file_issues in eslint_data.items():
                            if isinstance(file_issues, list):
                                issues.extend([f"{file_path}: {issue.get('message', '')}" for issue in file_issues])
                    except:
                        # å¦‚æœä¸æ˜¯ JSONï¼Œè§£ææ–‡æœ¬è¾“å‡º
                        for line in output.split('\n'):
                            if line.strip() and ('error' in line.lower() or 'warning' in line.lower()):
                                issues.append(line.strip())
            except:
                pass
        
        self.results['eslint'] = {
            'status': 'pass' if returncode == 0 else 'fail',
            'issue_count': len(issues),
            'issues': issues[:50]
        }
        
        return returncode == 0
    
    def analyze_file_complexity(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å¤æ‚åº¦"""
        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # åŸºæœ¬ç»Ÿè®¡
            total_lines = len(lines)
            code_lines = len([l for l in lines if l.strip() and not l.strip().startswith('//') and not l.strip().startswith('/*')])
            comment_lines = len([l for l in lines if '//' in l or '/*' in l or '*/' in l])
            blank_lines = len([l for l in lines if not l.strip()])
            
            # å¤æ‚åº¦æŒ‡æ ‡
            function_count = len(re.findall(r'(?:function|const|let|var)\s+\w+\s*[=:]', content))
            class_count = len(re.findall(r'class\s+\w+', content))
            import_count = len(re.findall(r'^import\s+', content, re.MULTILINE))
            export_count = len(re.findall(r'^export\s+', content, re.MULTILINE))
            
            # åµŒå¥—æ·±åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
            max_depth = 0
            current_depth = 0
            for char in content:
                if char == '{':
                    current_depth += 1
                    max_depth = max(max_depth, current_depth)
                elif char == '}':
                    current_depth = max(0, current_depth - 1)
            
            # æ–‡ä»¶å¤§å°è­¦å‘Š
            size_warning = None
            file_size_kb = file_path.stat().st_size / 1024
            if file_size_kb > 100:
                size_warning = f"æ–‡ä»¶è¿‡å¤§ ({file_size_kb:.1f} KB)"
            
            return {
                'total_lines': total_lines,
                'code_lines': code_lines,
                'comment_lines': comment_lines,
                'blank_lines': blank_lines,
                'function_count': function_count,
                'class_count': class_count,
                'import_count': import_count,
                'export_count': export_count,
                'max_nesting_depth': max_depth,
                'file_size_kb': round(file_size_kb, 2),
                'size_warning': size_warning,
                'complexity_score': function_count * 2 + class_count * 3 + max_depth * 2
            }
        except Exception as e:
            return {'error': str(e)}
    
    def analyze_code_quality(self):
        """åˆ†æä»£ç è´¨é‡"""
        print("ğŸ” åˆ†æä»£ç è´¨é‡...")
        
        source_dirs = ['app', 'lib', 'components', 'types']
        files_analyzed = []
        issues = []
        
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path):
                        continue
                
                analysis = self.analyze_file_complexity(file_path)
                if 'error' not in analysis:
                    files_analyzed.append({
                        'path': str(file_path.relative_to(self.project_root)),
                        **analysis
                    })
                    
                    # æ£€æŸ¥æ½œåœ¨é—®é¢˜
                    if analysis.get('complexity_score', 0) > 50:
                        issues.append(f"{file_path.relative_to(self.project_root)}: å¤æ‚åº¦è¾ƒé«˜ (score: {analysis['complexity_score']})")
                    if analysis.get('max_nesting_depth', 0) > 5:
                        issues.append(f"{file_path.relative_to(self.project_root)}: åµŒå¥—æ·±åº¦è¿‡æ·± ({analysis['max_nesting_depth']})")
                    if analysis.get('size_warning'):
                        issues.append(f"{file_path.relative_to(self.project_root)}: {analysis['size_warning']}")
        
        # ç»Ÿè®¡
        total_files = len(files_analyzed)
        avg_complexity = sum(f.get('complexity_score', 0) for f in files_analyzed) / total_files if total_files > 0 else 0
        large_files = [f for f in files_analyzed if f.get('file_size_kb', 0) > 50]
        complex_files = [f for f in files_analyzed if f.get('complexity_score', 0) > 30]
        
        self.results['code_quality'] = {
            'total_files_analyzed': total_files,
            'average_complexity': round(avg_complexity, 2),
            'large_files_count': len(large_files),
            'complex_files_count': len(complex_files),
            'large_files': [{'path': f['path'], 'size_kb': f['file_size_kb']} for f in large_files[:10]],
            'complex_files': [{'path': f['path'], 'score': f['complexity_score']} for f in complex_files[:10]],
            'issues': issues[:50]
        }
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–å…³ç³»"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–å…³ç³»...")
        
        package_json = self.project_root / 'package.json'
        if not package_json.exists():
            return
        
        with open(package_json, 'r', encoding='utf-8') as f:
            package_data = json.load(f)
        
        dependencies = package_data.get('dependencies', {})
        dev_dependencies = package_data.get('devDependencies', {})
        
        # æ£€æŸ¥è¿‡æ—¶çš„ä¾èµ–
        outdated = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'outdated', '--json'])
            if returncode == 0 and stdout:
                try:
                    outdated_data = json.loads(stdout)
                    outdated = list(outdated_data.keys())
                except:
                    pass
        except:
            pass
        
        # æ£€æŸ¥å®‰å…¨æ¼æ´
        vulnerabilities = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'audit', '--json'])
            if returncode != 0 and stdout:
                try:
                    audit_data = json.loads(stdout)
                    if 'vulnerabilities' in audit_data:
                        for vuln_id, vuln_data in audit_data['vulnerabilities'].items():
                            if isinstance(vuln_data, dict) and vuln_data.get('severity'):
                                vulnerabilities.append({
                                    'id': vuln_id,
                                    'severity': vuln_data.get('severity'),
                                    'title': vuln_data.get('title', ''),
                                    'via': vuln_data.get('via', [])
                                })
                except:
                    pass
        except:
            pass
        
        self.results['dependencies'] = {
            'total_dependencies': len(dependencies),
            'total_dev_dependencies': len(dev_dependencies),
            'outdated_count': len(outdated),
            'outdated_packages': outdated[:20],
            'vulnerabilities_count': len(vulnerabilities),
            'vulnerabilities': vulnerabilities[:20]
        }
    
    def check_unused_imports(self):
        """æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥ï¼ˆé€šè¿‡ TypeScript æ£€æŸ¥ï¼‰"""
        print("ğŸ” æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥...")
        
        unused_issues = []
        returncode, stdout, stderr = self.run_command(['npx', 'tsc', '--noEmit', '--pretty', 'false'])
        
        if returncode != 0:
            output = stderr + stdout
            for line in output.split('\n'):
                if 'is declared but its value is never read' in line or 'is declared but never used' in line:
                    unused_issues.append(line.strip())
        
        self.results['code_quality']['unused_imports'] = {
            'count': len(unused_issues),
            'issues': unused_issues[:30]
        }
    
    def check_security(self):
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        print("ğŸ” æ£€æŸ¥å®‰å…¨é—®é¢˜...")
        
        security_issues = []
        
        # æ£€æŸ¥ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
        sensitive_patterns = [
            (r'password\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†ç '),
            (r'api[_-]?key\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  API Key'),
            (r'secret\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†é’¥'),
            (r'token\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  Token'),
        ]
        
        source_dirs = ['app', 'lib', 'components']
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx', 'js', 'jsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path) or '__tests__' in str(file_path):
                        continue
                
                try:
                    content = file_path.read_text(encoding='utf-8')
                    for pattern, issue_type in sensitive_patterns:
                        matches = re.finditer(pattern, content, re.IGNORECASE)
                        for match in matches:
                            # æ’é™¤æ˜æ˜¾çš„ç¤ºä¾‹æˆ–æ³¨é‡Š
                            if 'example' not in match.group(0).lower() and 'TODO' not in match.group(0):
                                security_issues.append({
                                    'file': str(file_path.relative_to(self.project_root)),
                                    'type': issue_type,
                                    'line': content[:match.start()].count('\n') + 1
                                })
                except:
                    pass
        
        self.results['security'] = {
            'hardcoded_secrets_count': len(security_issues),
            'issues': security_issues[:30]
        }
    
    def check_test_coverage(self):
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡...")
        
        test_files = list((self.project_root / 'lib' / '__tests__').glob('*.test.ts'))
        test_count = len(test_files)
        
        # å°è¯•è¿è¡Œæµ‹è¯•
        test_status = 'unknown'
        test_output = ''
        try:
            returncode, stdout, stderr = self.run_command(['npm', 'test', '--', '--passWithNoTests'])
            test_status = 'pass' if returncode == 0 else 'fail'
            test_output = stdout + stderr
        except:
            pass
        
        self.results['code_quality']['testing'] = {
            'test_files_count': test_count,
            'test_status': test_status,
            'test_files': [str(f.name) for f in test_files]
        }
    
    def generate_summary(self):
        """ç”Ÿæˆæ€»ç»“"""
        summary = {
            'overall_status': 'pass',
            'issues_found': 0,
            'critical_issues': [],
            'warnings': []
        }
        
        # TypeScript é”™è¯¯
        if self.results['typescript'].get('error_count', 0) > 0:
            summary['issues_found'] += self.results['typescript']['error_count']
            summary['critical_issues'].append(f"TypeScript é”™è¯¯: {self.results['typescript']['error_count']} ä¸ª")
            summary['overall_status'] = 'fail'
        
        # ESLint é”™è¯¯
        if self.results['eslint'].get('issue_count', 0) > 0:
            summary['issues_found'] += self.results['eslint']['issue_count']
            summary['warnings'].append(f"ESLint é—®é¢˜: {self.results['eslint']['issue_count']} ä¸ª")
        
        # å®‰å…¨é—®é¢˜
        if self.results['security'].get('hardcoded_secrets_count', 0) > 0:
            summary['issues_found'] += self.results['security']['hardcoded_secrets_count']
            summary['critical_issues'].append(f"å®‰å…¨é—®é¢˜: {self.results['security']['hardcoded_secrets_count']} ä¸ªæ½œåœ¨ç¡¬ç¼–ç å¯†é’¥")
            summary['overall_status'] = 'fail'
        
        # ä¾èµ–æ¼æ´
        if self.results['dependencies'].get('vulnerabilities_count', 0) > 0:
            summary['issues_found'] += self.results['dependencies']['vulnerabilities_count']
            summary['warnings'].append(f"ä¾èµ–æ¼æ´: {self.results['dependencies']['vulnerabilities_count']} ä¸ª")
        
        # æœªä½¿ç”¨çš„å¯¼å…¥
        unused_count = self.results['code_quality'].get('unused_imports', {}).get('count', 0)
        if unused_count > 0:
            summary['issues_found'] += unused_count
            summary['warnings'].append(f"æœªä½¿ç”¨çš„å¯¼å…¥: {unused_count} ä¸ª")
        
        self.results['summary'] = summary
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹ä»£ç å¥åº·åº¦æ£€æŸ¥...\n")
        
        self.check_typescript()
        self.check_eslint()
        self.analyze_code_quality()
        self.check_unused_imports()
        self.check_dependencies()
        self.check_security()
        self.check_test_coverage()
        self.generate_summary()
        
        print("\nâœ… æ£€æŸ¥å®Œæˆ!")
    
    def generate_markdown_report(self) -> str:
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        md = []
        md.append("# ä»£ç å¥åº·åº¦æ£€æŸ¥æŠ¥å‘Š")
        md.append("")
        md.append(f"**ç”Ÿæˆæ—¶é—´**: {self.results['timestamp']}")
        md.append("")
        
        # æ€»ç»“
        summary = self.results['summary']
        status_emoji = "âŒ" if summary['overall_status'] == 'fail' else "âœ…"
        md.append(f"## ğŸ“Š æ€»ä½“çŠ¶æ€: {status_emoji} {summary['overall_status'].upper()}")
        md.append("")
        md.append(f"- **å‘ç°é—®é¢˜æ€»æ•°**: {summary['issues_found']}")
        md.append(f"- **ä¸¥é‡é—®é¢˜**: {len(summary['critical_issues'])}")
        md.append(f"- **è­¦å‘Š**: {len(summary['warnings'])}")
        md.append("")
        
        if summary['critical_issues']:
            md.append("### âš ï¸ ä¸¥é‡é—®é¢˜")
            for issue in summary['critical_issues']:
                md.append(f"- {issue}")
            md.append("")
        
        if summary['warnings']:
            md.append("### âš ï¸ è­¦å‘Š")
            for warning in summary['warnings']:
                md.append(f"- {warning}")
            md.append("")
        
        # TypeScript æ£€æŸ¥
        md.append("## ğŸ”· TypeScript æ£€æŸ¥")
        md.append("")
        ts_result = self.results['typescript']
        status_emoji = "âœ…" if ts_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {ts_result.get('status', 'unknown').upper()}")
        md.append(f"- **é”™è¯¯æ•°**: {ts_result.get('error_count', 0)}")
        md.append(f"- **è­¦å‘Šæ•°**: {ts_result.get('warning_count', 0)}")
        md.append("")
        
        if ts_result.get('errors'):
            md.append("### é”™è¯¯åˆ—è¡¨ (å‰ 20 ä¸ª)")
            for error in ts_result['errors'][:20]:
                md.append(f"- `{error}`")
            md.append("")
        
        # ESLint æ£€æŸ¥
        md.append("## ğŸ”¶ ESLint æ£€æŸ¥")
        md.append("")
        eslint_result = self.results['eslint']
        status_emoji = "âœ…" if eslint_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {eslint_result.get('status', 'unknown').upper()}")
        md.append(f"- **é—®é¢˜æ•°**: {eslint_result.get('issue_count', 0)}")
        md.append("")
        
        # ä»£ç è´¨é‡
        md.append("## ğŸ“ˆ ä»£ç è´¨é‡åˆ†æ")
        md.append("")
        cq = self.results['code_quality']
        md.append(f"- **åˆ†ææ–‡ä»¶æ•°**: {cq.get('total_files_analyzed', 0)}")
        md.append(f"- **å¹³å‡å¤æ‚åº¦**: {cq.get('average_complexity', 0)}")
        md.append(f"- **å¤§æ–‡ä»¶æ•°** (>50KB): {cq.get('large_files_count', 0)}")
        md.append(f"- **å¤æ‚æ–‡ä»¶æ•°** (score>30): {cq.get('complex_files_count', 0)}")
        md.append("")
        
        if cq.get('large_files'):
            md.append("### å¤§æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['large_files']:
                md.append(f"- `{file_info['path']}` ({file_info['size_kb']} KB)")
            md.append("")
        
        if cq.get('complex_files'):
            md.append("### å¤æ‚æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['complex_files']:
                md.append(f"- `{file_info['path']}` (å¤æ‚åº¦: {file_info['score']})")
            md.append("")
        
        unused_imports = cq.get('unused_imports', {})
        if unused_imports.get('count', 0) > 0:
            md.append(f"### æœªä½¿ç”¨çš„å¯¼å…¥ ({unused_imports['count']} ä¸ª)")
            for issue in unused_imports.get('issues', [])[:20]:
                md.append(f"- `{issue}`")
            md.append("")
        
        # ä¾èµ–å…³ç³»
        md.append("## ğŸ“¦ ä¾èµ–å…³ç³»")
        md.append("")
        deps = self.results['dependencies']
        md.append(f"- **ç”Ÿäº§ä¾èµ–**: {deps.get('total_dependencies', 0)}")
        md.append(f"- **å¼€å‘ä¾èµ–**: {deps.get('total_dev_dependencies', 0)}")
        md.append(f"- **è¿‡æ—¶åŒ…æ•°**: {deps.get('outdated_count', 0)}")
        md.append(f"- **å®‰å…¨æ¼æ´**: {deps.get('vulnerabilities_count', 0)}")
        md.append("")
        
        if deps.get('vulnerabilities'):
            md.append("### å®‰å…¨æ¼æ´")
            for vuln in deps['vulnerabilities'][:10]:
                md.append(f"- **{vuln.get('id', 'Unknown')}** ({vuln.get('severity', 'unknown')})")
                if vuln.get('title'):
                    md.append(f"  - {vuln['title']}")
            md.append("")
        
        # å®‰å…¨é—®é¢˜
        md.append("## ğŸ”’ å®‰å…¨æ£€æŸ¥")
        md.append("")
        sec = self.results['security']
        md.append(f"- **æ½œåœ¨ç¡¬ç¼–ç å¯†é’¥**: {sec.get('hardcoded_secrets_count', 0)}")
        md.append("")
        
        if sec.get('issues'):
            md.append("### æ½œåœ¨å®‰å…¨é—®é¢˜")
            for issue in sec['issues'][:20]:
                md.append(f"- `{issue['file']}:{issue['line']}` - {issue['type']}")
            md.append("")
        
        # æµ‹è¯•
        md.append("## ğŸ§ª æµ‹è¯•")
        md.append("")
        testing = cq.get('testing', {})
        md.append(f"- **æµ‹è¯•æ–‡ä»¶æ•°**: {testing.get('test_files_count', 0)}")
        md.append(f"- **æµ‹è¯•çŠ¶æ€**: {testing.get('test_status', 'unknown')}")
        if testing.get('test_files'):
            md.append("### æµ‹è¯•æ–‡ä»¶åˆ—è¡¨")
            for test_file in testing['test_files']:
                md.append(f"- `{test_file}`")
            md.append("")
        
        # å»ºè®®
        md.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
        md.append("")
        
        suggestions = []
        if ts_result.get('error_count', 0) > 0:
            suggestions.append("ä¿®å¤æ‰€æœ‰ TypeScript ç¼–è¯‘é”™è¯¯")
        if eslint_result.get('issue_count', 0) > 0:
            suggestions.append("ä¿®å¤ ESLint ä»£ç é£æ ¼é—®é¢˜")
        if deps.get('vulnerabilities_count', 0) > 0:
            suggestions.append("æ›´æ–°æœ‰å®‰å…¨æ¼æ´çš„ä¾èµ–åŒ…")
        if unused_imports.get('count', 0) > 0:
            suggestions.append("æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥")
        if cq.get('complex_files_count', 0) > 0:
            suggestions.append("é‡æ„å¤æ‚åº¦è¿‡é«˜çš„æ–‡ä»¶ï¼Œæé«˜å¯ç»´æŠ¤æ€§")
        if sec.get('hardcoded_secrets_count', 0) > 0:
            suggestions.append("ç§»é™¤ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡")
        if testing.get('test_files_count', 0) < 5:
            suggestions.append("å¢åŠ æµ‹è¯•è¦†ç›–ç‡ï¼Œæé«˜ä»£ç è´¨é‡")
        
        if suggestions:
            for i, suggestion in enumerate(suggestions, 1):
                md.append(f"{i}. {suggestion}")
        else:
            md.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
        md.append("")
        md.append("---")
        md.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.results['timestamp']}*")
        
        return "\n".join(md)


def main():
    project_root = Path(__file__).parent.parent
    checker = CodeHealthChecker(str(project_root))
    
    checker.run_all_checks()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_markdown_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = project_root / 'CODE_HEALTH_REPORT.md'
    report_path.write_text(report, encoding='utf-8')
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print("\n" + "="*60)
    print(report)
    print("="*60)


if __name__ == '__main__':
    main()

