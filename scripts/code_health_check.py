#!/usr/bin/env python3
"""
ä»£ç å¥åº·åº¦å…¨é¢æ£€æŸ¥è„šæœ¬
æ£€æŸ¥ TypeScript é”™è¯¯ã€ä»£ç è´¨é‡ã€ä¾èµ–å…³ç³»ã€æµ‹è¯•è¦†ç›–ç‡ç­‰
"""

import os
import json
import subprocess
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Any
import ast

class CodeHealthChecker:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'typescript': {},
            'eslint': {},
            'eslint_complexity': {},
            'dead_code': {},
            'dependency_health': {},
            'code_quality': {},
            'dependencies': {},
            'file_analysis': {},
            'security': {},
            'performance': {},
            'summary': {}
        }
        
    def run_command(self, cmd: List[str], cwd: str = None, timeout: int = 300) -> Tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœï¼ˆå®Œæ•´æ£€æŸ¥æ¨¡å¼ï¼Œå…è®¸æ›´é•¿æ—¶é—´ï¼‰"""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd or self.project_root,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Command timeout"
        except Exception as e:
            return -1, "", str(e)
    
    def check_typescript(self):
        """æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ TypeScript ç¼–è¯‘é”™è¯¯...")
        returncode, stdout, stderr = self.run_command(['npx', 'tsc', '--noEmit', '--pretty', 'false'], timeout=120)
        
        errors = []
        warnings = []
        
        if returncode != 0:
            output = stderr + stdout
            lines = output.split('\n')
            for line in lines:
                if 'error TS' in line:
                    errors.append(line.strip())
                elif 'warning TS' in line:
                    warnings.append(line.strip())
        
        self.results['typescript'] = {
            'status': 'pass' if returncode == 0 else 'fail',
            'error_count': len(errors),
            'warning_count': len(warnings),
            'errors': errors[:50],  # é™åˆ¶è¾“å‡º
            'warnings': warnings[:50]
        }
        
        return returncode == 0
    
    def check_eslint(self):
        """æ£€æŸ¥ ESLint é”™è¯¯"""
        print("ğŸ” æ£€æŸ¥ ESLint é”™è¯¯...")
        # ä½¿ç”¨æ›´å¿«çš„æ£€æŸ¥æ–¹å¼ï¼Œé™åˆ¶æ–‡ä»¶æ•°é‡
        returncode, stdout, stderr = self.run_command([
            'npx', 'eslint', 
            '--format', 'json',
            'app', 'lib', 'components', 'types'
        ], timeout=120)
        
        issues = []
        error_count = 0
        warning_count = 0
        
        # åªå¤„ç† stdoutï¼Œå¿½ç•¥ stderrï¼ˆé¿å… JSON æ±¡æŸ“ï¼‰
        if stdout:
            try:
                # å°è¯•è§£æ JSONï¼ˆåªä» stdoutï¼‰
                eslint_data = json.loads(stdout)
                if isinstance(eslint_data, list):
                    # ESLint JSON æ ¼å¼æ˜¯æ•°ç»„
                    for file_data in eslint_data:
                        if isinstance(file_data, dict):
                            file_path = file_data.get('filePath', '')
                            file_issues = file_data.get('messages', [])
                            for issue in file_issues:
                                severity = issue.get('severity', 1)
                                if severity == 2:
                                    error_count += 1
                                elif severity == 1:
                                    warning_count += 1
                                issues.append({
                                    'file': file_path,
                                    'line': issue.get('line', 0),
                                    'column': issue.get('column', 0),
                                    'severity': 'error' if severity == 2 else 'warning',
                                    'message': issue.get('message', ''),
                                    'rule': issue.get('ruleId', '')
                                })
                elif isinstance(eslint_data, dict):
                    # æ—§æ ¼å¼ï¼šå¯¹è±¡
                    for file_path, file_issues in eslint_data.items():
                        if isinstance(file_issues, list):
                            for issue in file_issues:
                                severity = issue.get('severity', 1)
                                if severity == 2:
                                    error_count += 1
                                elif severity == 1:
                                    warning_count += 1
                                issues.append({
                                    'file': file_path,
                                    'line': issue.get('line', 0),
                                    'column': issue.get('column', 0),
                                    'severity': 'error' if severity == 2 else 'warning',
                                    'message': issue.get('message', ''),
                                    'rule': issue.get('ruleId', '')
                                })
            except (json.JSONDecodeError, KeyError, ValueError):
                # JSON è§£æå¤±è´¥ï¼Œå¿½ç•¥ï¼ˆé¿å…æ±¡æŸ“æŠ¥å‘Šï¼‰
                pass
        
        self.results['eslint'] = {
            'status': 'pass' if returncode == 0 and error_count == 0 else 'fail',
            'error_count': error_count,
            'warning_count': warning_count,
            'issue_count': len(issues),
            'issues': issues[:30]  # å‡å°‘è¾“å‡º
        }
        
        return returncode == 0 and error_count == 0
    
    def check_eslint_complexity(self):
        """æ£€æŸ¥ ESLint å¤æ‚åº¦è§„åˆ™ï¼ˆä»ä¸» ESLint æ£€æŸ¥ç»“æœä¸­æå–ï¼‰"""
        print("ğŸ” æ£€æŸ¥ ESLint å¤æ‚åº¦è§„åˆ™...")
        
        # ä»ä¸» ESLint æ£€æŸ¥ç»“æœä¸­æå–å¤æ‚åº¦é—®é¢˜ï¼Œé¿å…é‡å¤è¿è¡Œ
        complexity_issues = []
        complexity_rules = ['complexity', 'max-depth', 'max-lines', 'max-lines-per-function', 'max-nested-callbacks', 'max-params']
        
        eslint_issues = self.results.get('eslint', {}).get('issues', [])
        for issue in eslint_issues:
            if isinstance(issue, dict):
                rule_id = issue.get('rule', '')
                if any(rule in rule_id.lower() for rule in complexity_rules):
                    complexity_issues.append({
                        'file': issue.get('file', ''),
                        'line': issue.get('line', 0),
                        'rule': rule_id,
                        'message': issue.get('message', '')
                    })
        
        self.results['eslint_complexity'] = {
            'issue_count': len(complexity_issues),
            'issues': complexity_issues[:20]  # å‡å°‘è¾“å‡º
        }
    
    def check_dead_code(self):
        """ä½¿ç”¨ ts-prune æ£€æŸ¥æ­»ä»£ç """
        print("ğŸ” æ£€æŸ¥æ­»ä»£ç  (ts-prune)...")
        
        # ä½¿ç”¨æ›´å¿«çš„é…ç½®ï¼Œè·³è¿‡ node_modules å’Œ .next
        returncode, stdout, stderr = self.run_command([
            'npx', 'ts-prune',
            '--ignore', 'node_modules',
            '--ignore', '.next'
        ], timeout=60)
        
        dead_code_issues = []
        if stdout:
            lines = stdout.split('\n')
            for line in lines[:200]:  # é™åˆ¶å¤„ç†è¡Œæ•°
                line = line.strip()
                if line and not line.startswith('Found') and 'node_modules' not in line and '.next' not in line:
                    # è§£æ ts-prune è¾“å‡ºæ ¼å¼: file.ts:line - exportName
                    if ' - ' in line:
                        parts = line.split(' - ')
                        if len(parts) == 2:
                            file_info = parts[0].split(':')
                            try:
                                dead_code_issues.append({
                                    'file': file_info[0] if file_info else parts[0],
                                    'line': int(file_info[1]) if len(file_info) > 1 and file_info[1].isdigit() else 0,
                                    'export': parts[1].strip()
                                })
                            except (ValueError, IndexError):
                                pass
                    elif line and not line.startswith('Found'):
                        dead_code_issues.append({'file': line})
        
        self.results['dead_code'] = {
            'status': 'pass' if len(dead_code_issues) == 0 else 'warning',
            'issue_count': len(dead_code_issues),
            'issues': dead_code_issues[:30]  # å‡å°‘è¾“å‡º
        }
    
    def check_dependency_health(self):
        """ä½¿ç”¨ depcheck æ£€æŸ¥ä¾èµ–å¥åº·"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–å¥åº· (depcheck)...")
        
        returncode, stdout, stderr = self.run_command(['npx', 'depcheck', '--json'], timeout=60)
        
        unused_deps = []
        missing_deps = []
        
        # åªå¤„ç† stdoutï¼Œç¡®ä¿ JSON è§£æ
        if stdout:
            try:
                depcheck_data = json.loads(stdout)
                if isinstance(depcheck_data, dict):
                    unused_deps = depcheck_data.get('dependencies', [])
                    missing_deps = list(depcheck_data.get('missing', {}).keys())
            except (json.JSONDecodeError, KeyError, ValueError):
                # JSON è§£æå¤±è´¥ï¼Œå¿½ç•¥
                pass
        
        self.results['dependency_health'] = {
            'status': 'pass' if len(unused_deps) == 0 and len(missing_deps) == 0 else 'warning',
            'unused_dependencies': unused_deps[:20],  # å‡å°‘è¾“å‡º
            'missing_dependencies': missing_deps[:20],
            'unused_count': len(unused_deps),
            'missing_count': len(missing_deps)
        }
    
    def analyze_file_complexity(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å¤æ‚åº¦"""
        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # åŸºæœ¬ç»Ÿè®¡
            total_lines = len(lines)
            code_lines = len([l for l in lines if l.strip() and not l.strip().startswith('//') and not l.strip().startswith('/*')])
            comment_lines = len([l for l in lines if '//' in l or '/*' in l or '*/' in l])
            blank_lines = len([l for l in lines if not l.strip()])
            
            # å¤æ‚åº¦æŒ‡æ ‡
            function_count = len(re.findall(r'(?:function|const|let|var)\s+\w+\s*[=:]', content))
            class_count = len(re.findall(r'class\s+\w+', content))
            import_count = len(re.findall(r'^import\s+', content, re.MULTILINE))
            export_count = len(re.findall(r'^export\s+', content, re.MULTILINE))
            
            # åµŒå¥—æ·±åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
            max_depth = 0
            current_depth = 0
            for char in content:
                if char == '{':
                    current_depth += 1
                    max_depth = max(max_depth, current_depth)
                elif char == '}':
                    current_depth = max(0, current_depth - 1)
            
            # æ–‡ä»¶å¤§å°è­¦å‘Š
            size_warning = None
            file_size_kb = file_path.stat().st_size / 1024
            if file_size_kb > 100:
                size_warning = f"æ–‡ä»¶è¿‡å¤§ ({file_size_kb:.1f} KB)"
            
            return {
                'total_lines': total_lines,
                'code_lines': code_lines,
                'comment_lines': comment_lines,
                'blank_lines': blank_lines,
                'function_count': function_count,
                'class_count': class_count,
                'import_count': import_count,
                'export_count': export_count,
                'max_nesting_depth': max_depth,
                'file_size_kb': round(file_size_kb, 2),
                'size_warning': size_warning,
                'complexity_score': function_count * 2 + class_count * 3 + max_depth * 2
            }
        except Exception as e:
            return {'error': str(e)}
    
    def analyze_code_quality(self):
        """åˆ†æä»£ç è´¨é‡"""
        print("ğŸ” åˆ†æä»£ç è´¨é‡...")
        
        source_dirs = ['app', 'lib', 'components', 'types']
        files_analyzed = []
        issues = []
        
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path) or '__tests__' in str(file_path):
                        continue
                    
                    try:
                        analysis = self.analyze_file_complexity(file_path)
                        if 'error' not in analysis:
                            files_analyzed.append({
                                'path': str(file_path.relative_to(self.project_root)),
                                **analysis
                            })
                            
                            # æ£€æŸ¥æ½œåœ¨é—®é¢˜
                            if analysis.get('complexity_score', 0) > 50:
                                issues.append(f"{file_path.relative_to(self.project_root)}: å¤æ‚åº¦è¾ƒé«˜ (score: {analysis['complexity_score']})")
                            if analysis.get('max_nesting_depth', 0) > 5:
                                issues.append(f"{file_path.relative_to(self.project_root)}: åµŒå¥—æ·±åº¦è¿‡æ·± ({analysis['max_nesting_depth']})")
                            if analysis.get('size_warning'):
                                issues.append(f"{file_path.relative_to(self.project_root)}: {analysis['size_warning']}")
                    except Exception:
                        # è·³è¿‡æ— æ³•åˆ†æçš„æ–‡ä»¶
                        continue
        
        # ç»Ÿè®¡
        total_files = len(files_analyzed)
        avg_complexity = sum(f.get('complexity_score', 0) for f in files_analyzed) / total_files if total_files > 0 else 0
        large_files = [f for f in files_analyzed if f.get('file_size_kb', 0) > 50]
        complex_files = [f for f in files_analyzed if f.get('complexity_score', 0) > 30]
        
        # ä»£ç è¡Œæ•°ç»Ÿè®¡
        total_lines = sum(f.get('total_lines', 0) for f in files_analyzed)
        total_code_lines = sum(f.get('code_lines', 0) for f in files_analyzed)
        total_comment_lines = sum(f.get('comment_lines', 0) for f in files_analyzed)
        total_blank_lines = sum(f.get('blank_lines', 0) for f in files_analyzed)
        
        # å‡½æ•°å’Œç±»ç»Ÿè®¡
        total_functions = sum(f.get('function_count', 0) for f in files_analyzed)
        total_classes = sum(f.get('class_count', 0) for f in files_analyzed)
        total_imports = sum(f.get('import_count', 0) for f in files_analyzed)
        total_exports = sum(f.get('export_count', 0) for f in files_analyzed)
        
        # æ–‡ä»¶å¤§å°åˆ†å¸ƒ
        small_files = len([f for f in files_analyzed if f.get('file_size_kb', 0) < 10])
        medium_files = len([f for f in files_analyzed if 10 <= f.get('file_size_kb', 0) < 30])
        large_files_count = len([f for f in files_analyzed if f.get('file_size_kb', 0) >= 30])
        
        self.results['code_quality'] = {
            'total_files_analyzed': total_files,
            'average_complexity': round(avg_complexity, 2),
            'large_files_count': len(large_files),
            'complex_files_count': len(complex_files),
            'large_files': [{'path': f['path'], 'size_kb': f['file_size_kb']} for f in large_files[:10]],
            'complex_files': [{'path': f['path'], 'score': f['complexity_score']} for f in complex_files[:10]],
            'issues': issues[:50],
            'code_statistics': {
                'total_lines': total_lines,
                'total_code_lines': total_code_lines,
                'total_comment_lines': total_comment_lines,
                'total_blank_lines': total_blank_lines,
                'total_functions': total_functions,
                'total_classes': total_classes,
                'total_imports': total_imports,
                'total_exports': total_exports,
                'file_size_distribution': {
                    'small': small_files,
                    'medium': medium_files,
                    'large': large_files_count
                }
            }
        }
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–å…³ç³»"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–å…³ç³»...")
        
        package_json = self.project_root / 'package.json'
        if not package_json.exists():
            return
        
        with open(package_json, 'r', encoding='utf-8') as f:
            package_data = json.load(f)
        
        dependencies = package_data.get('dependencies', {})
        dev_dependencies = package_data.get('devDependencies', {})
        
        # æ£€æŸ¥è¿‡æ—¶çš„ä¾èµ–
        outdated = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'outdated', '--json'], timeout=60)
            if returncode == 0 and stdout:
                try:
                    outdated_data = json.loads(stdout)
                    outdated = list(outdated_data.keys())
                except:
                    pass
        except:
            pass
        
        # æ£€æŸ¥å®‰å…¨æ¼æ´
        vulnerabilities = []
        try:
            returncode, stdout, _ = self.run_command(['npm', 'audit', '--json'], timeout=60)
            if returncode != 0 and stdout:
                try:
                    audit_data = json.loads(stdout)
                    if 'vulnerabilities' in audit_data:
                        for vuln_id, vuln_data in audit_data['vulnerabilities'].items():
                            if isinstance(vuln_data, dict) and vuln_data.get('severity'):
                                vulnerabilities.append({
                                    'id': vuln_id,
                                    'severity': vuln_data.get('severity'),
                                    'title': vuln_data.get('title', ''),
                                    'via': vuln_data.get('via', [])
                                })
                except (json.JSONDecodeError, KeyError):
                    pass
        except:
            pass
        
        self.results['dependencies'] = {
            'total_dependencies': len(dependencies),
            'total_dev_dependencies': len(dev_dependencies),
            'outdated_count': len(outdated),
            'outdated_packages': outdated[:20],
            'vulnerabilities_count': len(vulnerabilities),
            'vulnerabilities': vulnerabilities[:20]
        }
    
    def check_unused_imports(self):
        """æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥ï¼ˆä» TypeScript æ£€æŸ¥ç»“æœä¸­æå–ï¼Œé¿å…é‡å¤è¿è¡Œï¼‰"""
        print("ğŸ” æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥...")
        
        unused_issues = []
        # å¤ç”¨ TypeScript æ£€æŸ¥çš„è¾“å‡º
        ts_errors = self.results.get('typescript', {}).get('errors', [])
        for error in ts_errors:
            if 'is declared but its value is never read' in error or 'is declared but never used' in error:
                unused_issues.append(error.strip())
        
        self.results['code_quality']['unused_imports'] = {
            'count': len(unused_issues),
            'issues': unused_issues[:20]  # å‡å°‘è¾“å‡º
        }
    
    def check_security(self):
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        print("ğŸ” æ£€æŸ¥å®‰å…¨é—®é¢˜...")
        
        security_issues = []
        
        # æ£€æŸ¥ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
        sensitive_patterns = [
            (r'password\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†ç '),
            (r'api[_-]?key\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  API Key'),
            (r'secret\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç å¯†é’¥'),
            (r'token\s*[:=]\s*["\']([^"\']+)["\']', 'ç¡¬ç¼–ç  Token'),
        ]
        
        source_dirs = ['app', 'lib', 'components']
        for dir_name in source_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                continue
                
            for ext in ['ts', 'tsx', 'js', 'jsx']:
                for file_path in dir_path.rglob(f'*.{ext}'):
                    if 'node_modules' in str(file_path) or '.next' in str(file_path) or '__tests__' in str(file_path):
                        continue
                
                try:
                    content = file_path.read_text(encoding='utf-8')
                    for pattern, issue_type in sensitive_patterns:
                        matches = re.finditer(pattern, content, re.IGNORECASE)
                        for match in matches:
                            # æ’é™¤æ˜æ˜¾çš„ç¤ºä¾‹æˆ–æ³¨é‡Š
                            if 'example' not in match.group(0).lower() and 'TODO' not in match.group(0):
                                security_issues.append({
                                    'file': str(file_path.relative_to(self.project_root)),
                                    'type': issue_type,
                                    'line': content[:match.start()].count('\n') + 1
                                })
                except:
                    pass
        
        self.results['security'] = {
            'hardcoded_secrets_count': len(security_issues),
            'issues': security_issues[:30]
        }
    
    def check_test_coverage(self):
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡å’Œè¿è¡Œæµ‹è¯•"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡...")
        
        # æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        test_files = []
        test_dirs = [
            self.project_root / 'lib' / '__tests__',
            self.project_root / '__tests__',
            self.project_root / 'app',
            self.project_root / 'lib'
        ]
        
        for test_dir in test_dirs:
            if test_dir.exists():
                for pattern in ['*.test.ts', '*.test.tsx', '*.spec.ts', '*.spec.tsx']:
                    test_files.extend(list(test_dir.rglob(pattern)))
        
        # å»é‡
        test_files = list(set(test_files))
        test_count = len(test_files)
        
        # è¿è¡Œæµ‹è¯•è·å–è¦†ç›–ç‡
        test_status = 'unknown'
        coverage_data = {}
        try:
            returncode, stdout, stderr = self.run_command(['npm', 'test', '--', '--passWithNoTests', '--coverage', '--json'], timeout=120)
            if returncode == 0:
                test_status = 'pass'
            else:
                test_status = 'fail'
            
            # å°è¯•è§£æè¦†ç›–ç‡æ•°æ®
            if stdout:
                try:
                    coverage_data = json.loads(stdout)
                except:
                    pass
        except:
            pass
        
        self.results['code_quality']['testing'] = {
            'test_files_count': test_count,
            'test_status': test_status,
            'test_files': [str(f.relative_to(self.project_root)) for f in test_files],
            'coverage': coverage_data
        }
    
    def generate_summary(self):
        """ç”Ÿæˆæ€»ç»“"""
        summary = {
            'overall_status': 'pass',
            'issues_found': 0,
            'critical_issues': [],
            'warnings': []
        }
        
        # TypeScript é”™è¯¯
        if self.results['typescript'].get('error_count', 0) > 0:
            summary['issues_found'] += self.results['typescript']['error_count']
            summary['critical_issues'].append(f"TypeScript é”™è¯¯: {self.results['typescript']['error_count']} ä¸ª")
            summary['overall_status'] = 'fail'
        
        # ESLint é”™è¯¯
        eslint_errors = self.results['eslint'].get('error_count', 0)
        eslint_warnings = self.results['eslint'].get('warning_count', 0)
        if eslint_errors > 0:
            summary['issues_found'] += eslint_errors
            summary['critical_issues'].append(f"ESLint é”™è¯¯: {eslint_errors} ä¸ª")
            summary['overall_status'] = 'fail'
        if eslint_warnings > 0:
            summary['issues_found'] += eslint_warnings
            summary['warnings'].append(f"ESLint è­¦å‘Š: {eslint_warnings} ä¸ª")
        
        # ESLint å¤æ‚åº¦é—®é¢˜
        complexity_issues = self.results['eslint_complexity'].get('issue_count', 0)
        if complexity_issues > 0:
            summary['issues_found'] += complexity_issues
            summary['warnings'].append(f"ESLint å¤æ‚åº¦é—®é¢˜: {complexity_issues} ä¸ª")
        
        # æ­»ä»£ç 
        dead_code_count = self.results['dead_code'].get('issue_count', 0)
        if dead_code_count > 0:
            summary['issues_found'] += dead_code_count
            summary['warnings'].append(f"æ­»ä»£ç : {dead_code_count} ä¸ªæœªä½¿ç”¨çš„å¯¼å‡º")
        
        # ä¾èµ–å¥åº·
        unused_deps = self.results['dependency_health'].get('unused_count', 0)
        missing_deps = self.results['dependency_health'].get('missing_count', 0)
        if unused_deps > 0:
            summary['issues_found'] += unused_deps
            summary['warnings'].append(f"æœªä½¿ç”¨çš„ä¾èµ–: {unused_deps} ä¸ª")
        if missing_deps > 0:
            summary['issues_found'] += missing_deps
            summary['warnings'].append(f"ç¼ºå¤±çš„ä¾èµ–: {missing_deps} ä¸ª")
        
        # å®‰å…¨é—®é¢˜
        if self.results['security'].get('hardcoded_secrets_count', 0) > 0:
            summary['issues_found'] += self.results['security']['hardcoded_secrets_count']
            summary['critical_issues'].append(f"å®‰å…¨é—®é¢˜: {self.results['security']['hardcoded_secrets_count']} ä¸ªæ½œåœ¨ç¡¬ç¼–ç å¯†é’¥")
            summary['overall_status'] = 'fail'
        
        # ä¾èµ–æ¼æ´
        if self.results['dependencies'].get('vulnerabilities_count', 0) > 0:
            summary['issues_found'] += self.results['dependencies']['vulnerabilities_count']
            summary['warnings'].append(f"ä¾èµ–æ¼æ´: {self.results['dependencies']['vulnerabilities_count']} ä¸ª")
        
        # æœªä½¿ç”¨çš„å¯¼å…¥
        unused_count = self.results['code_quality'].get('unused_imports', {}).get('count', 0)
        if unused_count > 0:
            summary['issues_found'] += unused_count
            summary['warnings'].append(f"æœªä½¿ç”¨çš„å¯¼å…¥: {unused_count} ä¸ª")
        
        self.results['summary'] = summary
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå¿«é€Ÿæ‰§è¡Œï¼‰"""
        print("ğŸš€ å¼€å§‹ä»£ç å¥åº·åº¦æ£€æŸ¥...\n")
        
        # åŸºç¡€æ£€æŸ¥ï¼ˆå¿…é¡»ï¼‰
        self.check_typescript()
        self.check_eslint()
        self.check_eslint_complexity()  # ä» ESLint ç»“æœæå–ï¼Œä¸é‡å¤è¿è¡Œ
        
        # ä»£ç è´¨é‡æ£€æŸ¥ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        self.analyze_code_quality()  # é™åˆ¶æ–‡ä»¶æ•°é‡
        self.check_unused_imports()  # ä» TypeScript ç»“æœæå–
        self.check_dead_code()
        
        # ä¾èµ–æ£€æŸ¥ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        self.check_dependencies()  # è·³è¿‡è¿‡æ—¶æ£€æŸ¥
        self.check_dependency_health()
        
        # å®‰å…¨å’Œæµ‹è¯•ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        self.check_security()
        self.check_test_coverage()  # åªç»Ÿè®¡ï¼Œä¸è¿è¡Œ
        
        # ç”Ÿæˆæ€»ç»“
        self.generate_summary()
        
        print("\nâœ… æ£€æŸ¥å®Œæˆ!")
    
    def generate_markdown_report(self) -> str:
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        md = []
        md.append("# ä»£ç å¥åº·åº¦æ£€æŸ¥æŠ¥å‘Š")
        md.append("")
        md.append(f"**ç”Ÿæˆæ—¶é—´**: {self.results['timestamp']}")
        md.append("")
        
        # æ€»ç»“
        summary = self.results['summary']
        status_emoji = "âŒ" if summary['overall_status'] == 'fail' else "âœ…"
        md.append(f"## ğŸ“Š æ€»ä½“çŠ¶æ€: {status_emoji} {summary['overall_status'].upper()}")
        md.append("")
        md.append(f"- **å‘ç°é—®é¢˜æ€»æ•°**: {summary['issues_found']}")
        md.append(f"- **ä¸¥é‡é—®é¢˜**: {len(summary['critical_issues'])}")
        md.append(f"- **è­¦å‘Š**: {len(summary['warnings'])}")
        md.append("")
        
        if summary['critical_issues']:
            md.append("### âš ï¸ ä¸¥é‡é—®é¢˜")
            for issue in summary['critical_issues']:
                md.append(f"- {issue}")
            md.append("")
        
        if summary['warnings']:
            md.append("### âš ï¸ è­¦å‘Š")
            for warning in summary['warnings']:
                md.append(f"- {warning}")
            md.append("")
        
        # TypeScript æ£€æŸ¥
        md.append("## ğŸ”· TypeScript æ£€æŸ¥")
        md.append("")
        ts_result = self.results['typescript']
        status_emoji = "âœ…" if ts_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {ts_result.get('status', 'unknown').upper()}")
        md.append(f"- **é”™è¯¯æ•°**: {ts_result.get('error_count', 0)}")
        md.append(f"- **è­¦å‘Šæ•°**: {ts_result.get('warning_count', 0)}")
        md.append("")
        
        if ts_result.get('errors'):
            md.append("### é”™è¯¯åˆ—è¡¨ (å‰ 20 ä¸ª)")
            for error in ts_result['errors'][:20]:
                md.append(f"- `{error}`")
            md.append("")
        
        # ESLint æ£€æŸ¥
        md.append("## ğŸ”¶ ESLint æ£€æŸ¥")
        md.append("")
        eslint_result = self.results['eslint']
        status_emoji = "âœ…" if eslint_result.get('status') == 'pass' else "âŒ"
        md.append(f"**çŠ¶æ€**: {status_emoji} {eslint_result.get('status', 'unknown').upper()}")
        md.append(f"- **é”™è¯¯æ•°**: {eslint_result.get('error_count', 0)}")
        md.append(f"- **è­¦å‘Šæ•°**: {eslint_result.get('warning_count', 0)}")
        md.append(f"- **æ€»é—®é¢˜æ•°**: {eslint_result.get('issue_count', 0)}")
        md.append("")
        
        if eslint_result.get('issues'):
            md.append("### ä¸»è¦é—®é¢˜ (å‰ 10 ä¸ª)")
            for issue in eslint_result['issues'][:10]:
                if isinstance(issue, dict):
                    file_path = issue.get('file', 'unknown')
                    # ç§»é™¤ç»å¯¹è·¯å¾„å‰ç¼€ï¼Œåªä¿ç•™ç›¸å¯¹è·¯å¾„
                    if str(self.project_root) in file_path:
                        file_path = file_path.replace(str(self.project_root) + '/', '')
                    md.append(f"- `{file_path}:{issue.get('line', 0)}` - {issue.get('message', '')} [{issue.get('rule', '')}]")
                else:
                    md.append(f"- {issue}")
            md.append("")
        
        # ESLint å¤æ‚åº¦æ£€æŸ¥
        complexity_result = self.results.get('eslint_complexity', {})
        if complexity_result.get('issue_count', 0) > 0:
            md.append("### ğŸ” å¤æ‚åº¦è§„åˆ™æ£€æŸ¥")
            md.append("")
            md.append(f"- **å¤æ‚åº¦é—®é¢˜æ•°**: {complexity_result.get('issue_count', 0)}")
            if complexity_result.get('issues'):
                md.append("### å¤æ‚åº¦é—®é¢˜ (å‰ 10 ä¸ª)")
                for issue in complexity_result['issues'][:10]:
                    md.append(f"- `{issue.get('file', 'unknown')}:{issue.get('line', 0)}` - {issue.get('rule', '')}: {issue.get('message', '')}")
                md.append("")
        
        # æ­»ä»£ç æ£€æŸ¥
        md.append("## ğŸ’€ æ­»ä»£ç æ£€æŸ¥ (ts-prune)")
        md.append("")
        dead_code_result = self.results.get('dead_code', {})
        status_emoji = "âœ…" if dead_code_result.get('status') == 'pass' else "âš ï¸"
        md.append(f"**çŠ¶æ€**: {status_emoji} {dead_code_result.get('status', 'unknown').upper()}")
        md.append(f"- **æœªä½¿ç”¨çš„å¯¼å‡º**: {dead_code_result.get('issue_count', 0)}")
        md.append("")
        
        if dead_code_result.get('issues'):
            md.append("### æœªä½¿ç”¨çš„å¯¼å‡º (å‰ 20 ä¸ª)")
            for issue in dead_code_result['issues'][:20]:
                if isinstance(issue, dict):
                    export_name = issue.get('export', 'unknown')
                    file_path = issue.get('file', 'unknown')
                    line = issue.get('line', 0)
                    if line > 0:
                        md.append(f"- `{file_path}:{line}` - {export_name}")
                    else:
                        md.append(f"- `{file_path}` - {export_name}")
                else:
                    md.append(f"- {issue}")
            md.append("")
        
        # ä¾èµ–å¥åº·æ£€æŸ¥
        md.append("## ğŸ“¦ ä¾èµ–å¥åº·æ£€æŸ¥ (depcheck)")
        md.append("")
        dep_health_result = self.results.get('dependency_health', {})
        status_emoji = "âœ…" if dep_health_result.get('status') == 'pass' else "âš ï¸"
        md.append(f"**çŠ¶æ€**: {status_emoji} {dep_health_result.get('status', 'unknown').upper()}")
        md.append(f"- **æœªä½¿ç”¨çš„ä¾èµ–**: {dep_health_result.get('unused_count', 0)}")
        md.append(f"- **ç¼ºå¤±çš„ä¾èµ–**: {dep_health_result.get('missing_count', 0)}")
        md.append("")
        
        if dep_health_result.get('unused_dependencies'):
            md.append("### æœªä½¿ç”¨çš„ä¾èµ–")
            for dep in dep_health_result['unused_dependencies'][:20]:
                md.append(f"- `{dep}`")
            md.append("")
        
        if dep_health_result.get('missing_dependencies'):
            md.append("### ç¼ºå¤±çš„ä¾èµ–")
            for dep in dep_health_result['missing_dependencies'][:20]:
                md.append(f"- `{dep}`")
            md.append("")
        
        # ä»£ç è´¨é‡
        md.append("## ğŸ“ˆ ä»£ç è´¨é‡åˆ†æ")
        md.append("")
        cq = self.results['code_quality']
        md.append(f"- **åˆ†ææ–‡ä»¶æ•°**: {cq.get('total_files_analyzed', 0)}")
        md.append(f"- **å¹³å‡å¤æ‚åº¦**: {cq.get('average_complexity', 0)}")
        md.append(f"- **å¤§æ–‡ä»¶æ•°** (>50KB): {cq.get('large_files_count', 0)}")
        md.append(f"- **å¤æ‚æ–‡ä»¶æ•°** (score>30): {cq.get('complex_files_count', 0)}")
        md.append("")
        
        # ä»£ç ç»Ÿè®¡
        stats = cq.get('code_statistics', {})
        if stats:
            md.append("### ä»£ç ç»Ÿè®¡")
            md.append("")
            md.append(f"- **æ€»è¡Œæ•°**: {stats.get('total_lines', 0):,}")
            md.append(f"- **ä»£ç è¡Œæ•°**: {stats.get('total_code_lines', 0):,}")
            md.append(f"- **æ³¨é‡Šè¡Œæ•°**: {stats.get('total_comment_lines', 0):,}")
            md.append(f"- **ç©ºè¡Œæ•°**: {stats.get('total_blank_lines', 0):,}")
            md.append(f"- **å‡½æ•°æ•°**: {stats.get('total_functions', 0)}")
            md.append(f"- **ç±»æ•°**: {stats.get('total_classes', 0)}")
            md.append(f"- **å¯¼å…¥æ•°**: {stats.get('total_imports', 0)}")
            md.append(f"- **å¯¼å‡ºæ•°**: {stats.get('total_exports', 0)}")
            md.append("")
            
            dist = stats.get('file_size_distribution', {})
            if dist:
                md.append("### æ–‡ä»¶å¤§å°åˆ†å¸ƒ")
                md.append("")
                md.append(f"- **å°æ–‡ä»¶** (<10KB): {dist.get('small', 0)}")
                md.append(f"- **ä¸­æ–‡ä»¶** (10-30KB): {dist.get('medium', 0)}")
                md.append(f"- **å¤§æ–‡ä»¶** (â‰¥30KB): {dist.get('large', 0)}")
                md.append("")
        
        if cq.get('large_files'):
            md.append("### å¤§æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['large_files']:
                md.append(f"- `{file_info['path']}` ({file_info['size_kb']} KB)")
            md.append("")
        
        if cq.get('complex_files'):
            md.append("### å¤æ‚æ–‡ä»¶åˆ—è¡¨")
            for file_info in cq['complex_files']:
                md.append(f"- `{file_info['path']}` (å¤æ‚åº¦: {file_info['score']})")
            md.append("")
        
        unused_imports = cq.get('unused_imports', {})
        if unused_imports.get('count', 0) > 0:
            md.append(f"### æœªä½¿ç”¨çš„å¯¼å…¥ ({unused_imports['count']} ä¸ª)")
            for issue in unused_imports.get('issues', [])[:20]:
                md.append(f"- `{issue}`")
            md.append("")
        
        # ä¾èµ–å…³ç³»
        md.append("## ğŸ“¦ ä¾èµ–å…³ç³»")
        md.append("")
        deps = self.results['dependencies']
        md.append(f"- **ç”Ÿäº§ä¾èµ–**: {deps.get('total_dependencies', 0)}")
        md.append(f"- **å¼€å‘ä¾èµ–**: {deps.get('total_dev_dependencies', 0)}")
        md.append(f"- **è¿‡æ—¶åŒ…æ•°**: {deps.get('outdated_count', 0)}")
        md.append(f"- **å®‰å…¨æ¼æ´**: {deps.get('vulnerabilities_count', 0)}")
        md.append("")
        
        if deps.get('vulnerabilities'):
            md.append("### å®‰å…¨æ¼æ´")
            for vuln in deps['vulnerabilities'][:10]:
                md.append(f"- **{vuln.get('id', 'Unknown')}** ({vuln.get('severity', 'unknown')})")
                if vuln.get('title'):
                    md.append(f"  - {vuln['title']}")
            md.append("")
        
        # å®‰å…¨é—®é¢˜
        md.append("## ğŸ”’ å®‰å…¨æ£€æŸ¥")
        md.append("")
        sec = self.results['security']
        md.append(f"- **æ½œåœ¨ç¡¬ç¼–ç å¯†é’¥**: {sec.get('hardcoded_secrets_count', 0)}")
        md.append("")
        
        if sec.get('issues'):
            md.append("### æ½œåœ¨å®‰å…¨é—®é¢˜")
            for issue in sec['issues'][:20]:
                md.append(f"- `{issue['file']}:{issue['line']}` - {issue['type']}")
            md.append("")
        
        # æµ‹è¯•
        md.append("## ğŸ§ª æµ‹è¯•")
        md.append("")
        testing = cq.get('testing', {})
        md.append(f"- **æµ‹è¯•æ–‡ä»¶æ•°**: {testing.get('test_files_count', 0)}")
        md.append(f"- **æµ‹è¯•çŠ¶æ€**: {testing.get('test_status', 'unknown')}")
        if testing.get('test_files'):
            md.append("### æµ‹è¯•æ–‡ä»¶åˆ—è¡¨")
            for test_file in testing['test_files']:
                md.append(f"- `{test_file}`")
            md.append("")
        
        # è¯¦ç»†æ”¹è¿›å»ºè®®å’Œæ­¥éª¤
        md.append("## ğŸ’¡ æ”¹è¿›å»ºè®®ä¸è¡ŒåŠ¨è®¡åˆ’")
        md.append("")
        
        suggestions = []
        action_plans = []
        
        # P0: ä¸¥é‡é—®é¢˜
        if ts_result.get('error_count', 0) > 0:
            suggestions.append("ğŸ”´ **P0 - ç´§æ€¥**: ä¿®å¤æ‰€æœ‰ TypeScript ç¼–è¯‘é”™è¯¯")
            action_plans.append({
                'priority': 'P0',
                'title': 'ä¿®å¤ TypeScript ç¼–è¯‘é”™è¯¯',
                'count': ts_result.get('error_count', 0),
                'steps': [
                    'è¿è¡Œ `npm run type-check` æŸ¥çœ‹æ‰€æœ‰é”™è¯¯',
                    'é€ä¸ªä¿®å¤ç±»å‹é”™è¯¯',
                    'ä¼˜å…ˆä¿®å¤å½±å“æ„å»ºçš„é”™è¯¯',
                    'éªŒè¯ä¿®å¤åè¿è¡Œ `npm run build` ç¡®ä¿æ„å»ºæˆåŠŸ'
                ],
                'estimated_time': f"{ts_result.get('error_count', 0) * 5} åˆ†é’Ÿ"
            })
        
        if eslint_result.get('error_count', 0) > 0:
            suggestions.append("ğŸ”´ **P0 - ç´§æ€¥**: ä¿®å¤ ESLint é”™è¯¯")
            action_plans.append({
                'priority': 'P0',
                'title': 'ä¿®å¤ ESLint é”™è¯¯',
                'count': eslint_result.get('error_count', 0),
                'steps': [
                    'è¿è¡Œ `npm run lint` æŸ¥çœ‹æ‰€æœ‰é”™è¯¯',
                    'ä¼˜å…ˆä¿®å¤ React Hooks è§„åˆ™é”™è¯¯ï¼ˆå¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é—®é¢˜ï¼‰',
                    'ä¿®å¤ `@typescript-eslint/no-explicit-any` é”™è¯¯ï¼ˆç±»å‹å®‰å…¨ï¼‰',
                    'ä¿®å¤ `@typescript-eslint/no-unused-vars` é”™è¯¯ï¼ˆæ¸…ç†ä»£ç ï¼‰',
                    'ä½¿ç”¨ `npm run lint -- --fix` è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜',
                    'éªŒè¯ä¿®å¤åè¿è¡Œ `npm run build`'
                ],
                'estimated_time': f"{eslint_result.get('error_count', 0) * 3} åˆ†é’Ÿ"
            })
        
        if sec.get('hardcoded_secrets_count', 0) > 0:
            suggestions.append("ğŸ”´ **P0 - ç´§æ€¥**: ç§»é™¤ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯")
            action_plans.append({
                'priority': 'P0',
                'title': 'ç§»é™¤ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯',
                'count': sec.get('hardcoded_secrets_count', 0),
                'steps': [
                    'æ£€æŸ¥æŠ¥å‘Šä¸­çš„å®‰å…¨é—®é¢˜åˆ—è¡¨',
                    'å°†æ‰€æœ‰ç¡¬ç¼–ç çš„å¯†é’¥ã€å¯†ç ã€API Key ç§»åˆ°ç¯å¢ƒå˜é‡',
                    'æ›´æ–° `.env.local` å’Œ `.env.example`',
                    'ç¡®ä¿ `.env.local` åœ¨ `.gitignore` ä¸­',
                    'éªŒè¯ä»£ç ä¸­é€šè¿‡ `process.env` è¯»å–ç¯å¢ƒå˜é‡'
                ],
                'estimated_time': f"{sec.get('hardcoded_secrets_count', 0) * 10} åˆ†é’Ÿ"
            })
        
        # P1: é‡è¦é—®é¢˜
        if deps.get('vulnerabilities_count', 0) > 0:
            suggestions.append("ğŸŸ  **P1 - é‡è¦**: æ›´æ–°æœ‰å®‰å…¨æ¼æ´çš„ä¾èµ–åŒ…")
            action_plans.append({
                'priority': 'P1',
                'title': 'æ›´æ–°å®‰å…¨æ¼æ´ä¾èµ–',
                'count': deps.get('vulnerabilities_count', 0),
                'steps': [
                    'è¿è¡Œ `npm audit` æŸ¥çœ‹è¯¦ç»†æ¼æ´ä¿¡æ¯',
                    'è¿è¡Œ `npm audit fix` è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„æ¼æ´',
                    'å¯¹äºéœ€è¦æ‰‹åŠ¨æ›´æ–°çš„åŒ…ï¼Œæ£€æŸ¥ breaking changes',
                    'æ›´æ–°åè¿è¡Œ `npm test` ç¡®ä¿æµ‹è¯•é€šè¿‡',
                    'æ›´æ–°åè¿è¡Œ `npm run build` ç¡®ä¿æ„å»ºæˆåŠŸ'
                ],
                'estimated_time': '30-60 åˆ†é’Ÿ'
            })
        
        if unused_imports.get('count', 0) > 0:
            suggestions.append("ğŸŸ¡ **P1 - é‡è¦**: æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥")
            action_plans.append({
                'priority': 'P1',
                'title': 'æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥',
                'count': unused_imports.get('count', 0),
                'steps': [
                    'ä½¿ç”¨ IDE çš„è‡ªåŠ¨æ¸…ç†åŠŸèƒ½ï¼ˆå¦‚ VS Code çš„ Organize Importsï¼‰',
                    'æˆ–æ‰‹åŠ¨æ£€æŸ¥æŠ¥å‘Šä¸­çš„æœªä½¿ç”¨å¯¼å…¥åˆ—è¡¨',
                    'é€ä¸ªæ–‡ä»¶æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥',
                    'è¿è¡Œ `npm run type-check` éªŒè¯æ¸…ç†åæ— é”™è¯¯'
                ],
                'estimated_time': f"{unused_imports.get('count', 0) * 1} åˆ†é’Ÿ"
            })
        
        # P2: ä¼˜åŒ–å»ºè®®
        if cq.get('complex_files_count', 0) > 0:
            suggestions.append("ğŸŸ¢ **P2 - ä¼˜åŒ–**: é‡æ„å¤æ‚åº¦è¿‡é«˜çš„æ–‡ä»¶")
            complex_files = cq.get('complex_files', [])
            action_plans.append({
                'priority': 'P2',
                'title': 'é‡æ„å¤æ‚æ–‡ä»¶',
                'count': cq.get('complex_files_count', 0),
                'steps': [
                    'ä¼˜å…ˆé‡æ„å¤æ‚åº¦ > 50 çš„æ–‡ä»¶',
                    'å°†å¤§å‡½æ•°æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°',
                    'æå–é‡å¤é€»è¾‘ä¸ºå·¥å…·å‡½æ•°',
                    'ä½¿ç”¨è®¾è®¡æ¨¡å¼ç®€åŒ–å¤æ‚é€»è¾‘',
                    'æ·»åŠ å•å…ƒæµ‹è¯•ç¡®ä¿é‡æ„ååŠŸèƒ½ä¸å˜'
                ],
                'estimated_time': f"{cq.get('complex_files_count', 0) * 30} åˆ†é’Ÿ",
                'files': [f['path'] for f in complex_files[:10]]
            })
        
        dead_code_count = self.results.get('dead_code', {}).get('issue_count', 0)
        if dead_code_count > 0:
            suggestions.append("ğŸŸ¢ **P2 - ä¼˜åŒ–**: æ¸…ç†æ­»ä»£ç ")
            action_plans.append({
                'priority': 'P2',
                'title': 'æ¸…ç†æ­»ä»£ç ',
                'count': dead_code_count,
                'steps': [
                    'æ£€æŸ¥æŠ¥å‘Šä¸­çš„æœªä½¿ç”¨å¯¼å‡ºåˆ—è¡¨',
                    'ç¡®è®¤è¿™äº›å¯¼å‡ºç¡®å®æœªè¢«ä½¿ç”¨ï¼ˆæ£€æŸ¥æ˜¯å¦è¢«åŠ¨æ€å¯¼å…¥ï¼‰',
                    'åˆ é™¤ç¡®è®¤æœªä½¿ç”¨çš„å¯¼å‡º',
                    'æ³¨æ„ï¼šæŸäº›å¯¼å‡ºå¯èƒ½æ˜¯ä¸ºäº†æœªæ¥ä½¿ç”¨ï¼Œéœ€è°¨æ…åˆ é™¤'
                ],
                'estimated_time': f"{min(dead_code_count, 50) * 2} åˆ†é’Ÿ"
            })
        
        unused_deps = self.results.get('dependency_health', {}).get('unused_count', 0)
        if unused_deps > 0:
            suggestions.append("ğŸŸ¢ **P2 - ä¼˜åŒ–**: ç§»é™¤æœªä½¿ç”¨çš„ä¾èµ–")
            action_plans.append({
                'priority': 'P2',
                'title': 'ç§»é™¤æœªä½¿ç”¨çš„ä¾èµ–',
                'count': unused_deps,
                'steps': [
                    'æ£€æŸ¥æŠ¥å‘Šä¸­çš„æœªä½¿ç”¨ä¾èµ–åˆ—è¡¨',
                    'ç¡®è®¤è¿™äº›ä¾èµ–ç¡®å®æœªè¢«ä½¿ç”¨',
                    'è¿è¡Œ `npm uninstall <package>` ç§»é™¤',
                    'è¿è¡Œ `npm run build` ç¡®ä¿ç§»é™¤åæ— å½±å“'
                ],
                'estimated_time': '10 åˆ†é’Ÿ'
            })
        
        if testing.get('test_files_count', 0) < 10:
            suggestions.append("ğŸŸ¢ **P2 - ä¼˜åŒ–**: å¢åŠ æµ‹è¯•è¦†ç›–ç‡")
            action_plans.append({
                'priority': 'P2',
                'title': 'å¢åŠ æµ‹è¯•è¦†ç›–ç‡',
                'count': testing.get('test_files_count', 0),
                'steps': [
                    'ä¸ºæ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ·»åŠ å•å…ƒæµ‹è¯•',
                    'ä¸º API è·¯ç”±æ·»åŠ é›†æˆæµ‹è¯•',
                    'ä¸ºå·¥å…·å‡½æ•°æ·»åŠ æµ‹è¯•',
                    'ç›®æ ‡ï¼šæµ‹è¯•è¦†ç›–ç‡ > 70%',
                    'è¿è¡Œ `npm run test:coverage` æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š'
                ],
                'estimated_time': '2-4 å°æ—¶'
            })
        
        # è¾“å‡ºå»ºè®®æ‘˜è¦
        if suggestions:
            md.append("### ä¼˜å…ˆçº§æ‘˜è¦")
            md.append("")
            for suggestion in suggestions:
                md.append(f"- {suggestion}")
            md.append("")
        
        # è¾“å‡ºè¯¦ç»†è¡ŒåŠ¨è®¡åˆ’
        if action_plans:
            md.append("### è¯¦ç»†è¡ŒåŠ¨è®¡åˆ’")
            md.append("")
            
            # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
            p0_plans = [p for p in action_plans if p['priority'] == 'P0']
            p1_plans = [p for p in action_plans if p['priority'] == 'P1']
            p2_plans = [p for p in action_plans if p['priority'] == 'P2']
            
            for priority_group, plans in [('P0 - ç´§æ€¥', p0_plans), ('P1 - é‡è¦', p1_plans), ('P2 - ä¼˜åŒ–', p2_plans)]:
                if plans:
                    md.append(f"#### {priority_group}")
                    md.append("")
                    for plan in plans:
                        md.append(f"**{plan['title']}** ({plan['count']} ä¸ªé—®é¢˜)")
                        md.append("")
                        md.append(f"- **é¢„è®¡æ—¶é—´**: {plan.get('estimated_time', 'æœªçŸ¥')}")
                        md.append("- **æ‰§è¡Œæ­¥éª¤**:")
                        for i, step in enumerate(plan['steps'], 1):
                            md.append(f"  {i}. {step}")
                        if plan.get('files'):
                            md.append("- **ç›¸å…³æ–‡ä»¶**:")
                            for file_path in plan['files'][:5]:
                                md.append(f"  - `{file_path}`")
                        md.append("")
        
        if not suggestions:
            md.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
        md.append("")
        md.append("---")
        md.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.results['timestamp']}*")
        
        return "\n".join(md)


def main():
    project_root = Path(__file__).parent.parent
    checker = CodeHealthChecker(str(project_root))
    
    checker.run_all_checks()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_markdown_report()
    
    # ä¿å­˜æŠ¥å‘Šï¼ˆç¡®ä¿åªå†™å…¥ Markdownï¼Œä¸åŒ…å«ä»»ä½• JSONï¼‰
    report_path = project_root / 'CODE_HEALTH_REPORT.md'
    # ç¡®ä¿æŠ¥å‘Šæ˜¯çº¯ Markdown å­—ç¬¦ä¸²ï¼ˆç§»é™¤ä»»ä½• JSON æ±¡æŸ“ï¼‰
    if isinstance(report, str):
        lines = report.split('\n')
        clean_lines = []
        skip_next_n_lines = 0
        
        for i, line in enumerate(lines):
            # è·³è¿‡ JSON å—
            if skip_next_n_lines > 0:
                skip_next_n_lines -= 1
                continue
            
            # æ£€æµ‹ JSON å—å¼€å§‹æ ‡è®°
            if ('"filePath"' in line or '"messages"' in line) and ('[' in line or '{' in line):
                # è·³è¿‡æ•´ä¸ª JSON å¯¹è±¡/æ•°ç»„
                brace_count = line.count('{') + line.count('[') - line.count('}') - line.count(']')
                if brace_count > 0:
                    # ä¼°ç®—éœ€è¦è·³è¿‡çš„è¡Œæ•°ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
                    skip_next_n_lines = min(50, brace_count * 10)
                    continue
            
            # è·³è¿‡æ˜æ˜¾çš„ JSON è¡Œ
            if line.strip().startswith('{') and '"filePath"' in line:
                continue
            if line.strip().startswith('[') and '"filePath"' in line:
                continue
            if '"usedDeprecatedRules"' in line:
                continue
            
            clean_lines.append(line)
        
        report = '\n'.join(clean_lines)
    
    report_path.write_text(report, encoding='utf-8')
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print("\n" + "="*60)
    # åªæ‰“å°æŠ¥å‘Šçš„å‰ 100 è¡Œï¼Œé¿å…è¾“å‡ºè¿‡é•¿
    report_lines = report.split('\n')
    print('\n'.join(report_lines[:100]))
    if len(report_lines) > 100:
        print(f"\n... (æŠ¥å‘Šå…± {len(report_lines)} è¡Œï¼Œå·²æˆªæ–­)")
    print("="*60)


if __name__ == '__main__':
    main()

